{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>administration union territory daman diu revok...</td>\n",
       "      <td>sostok daman diu revokes mandatory rakshabandh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>malaika arora slammed instagram user trolled d...</td>\n",
       "      <td>sostok malaika slams user who trolled her for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>indira gandhi institute medical sciences igims...</td>\n",
       "      <td>sostok virgin now corrected to unmarried in ig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>lashkaretaibas kashmir commander abu dujana ki...</td>\n",
       "      <td>sostok aaj aapne pakad liya let man dujana bef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>hotels maharashtra train staff spot signs sex ...</td>\n",
       "      <td>sostok hotel staff to get training to spot sig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0  administration union territory daman diu revok...   \n",
       "1           1  malaika arora slammed instagram user trolled d...   \n",
       "2           2  indira gandhi institute medical sciences igims...   \n",
       "3           3  lashkaretaibas kashmir commander abu dujana ki...   \n",
       "4           4  hotels maharashtra train staff spot signs sex ...   \n",
       "\n",
       "                                             summary  \n",
       "0  sostok daman diu revokes mandatory rakshabandh...  \n",
       "1  sostok malaika slams user who trolled her for ...  \n",
       "2  sostok virgin now corrected to unmarried in ig...  \n",
       "3  sostok aaj aapne pakad liya let man dujana bef...  \n",
       "4  sostok hotel staff to get training to spot sig...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset/cleaned_news_summary.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_news = 47\n",
    "max_len_headline = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.text, data.summary, test_size=0.2, random_state=101, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed, Concatenate, Bidirectional\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from attention_my import AttentionLayer\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "physical_devices\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# run_opts = tf.Run(report_tensor_allocations_upon_oom = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_tokenizer = Tokenizer() \n",
    "# x_tokenizer.fit_on_texts(list(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh=4\n",
    "\n",
    "# cnt=0\n",
    "# tot_cnt=0\n",
    "# freq=0\n",
    "# tot_freq=0\n",
    "\n",
    "# for key,value in x_tokenizer.word_counts.items():\n",
    "#     tot_cnt=tot_cnt+1\n",
    "#     tot_freq=tot_freq+value\n",
    "#     if(value<thresh):\n",
    "#         cnt=cnt+1\n",
    "#         freq=freq+value\n",
    "    \n",
    "# print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "# print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokenizer = Tokenizer()\n",
    "X_tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "X_train_seq = X_tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = X_tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train = pad_sequences(X_train_seq, maxlen = max_len_news, padding='post')\n",
    "X_test = pad_sequences(X_test_seq, maxlen = max_len_news, padding='post')\n",
    "\n",
    "news_vocab_size = len(X_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #prepare a tokenizer for reviews on training data\n",
    "# y_tokenizer = Tokenizer()   \n",
    "# y_tokenizer.fit_on_texts(list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh=6\n",
    "\n",
    "# cnt=0\n",
    "# tot_cnt=0\n",
    "# freq=0\n",
    "# tot_freq=0\n",
    "\n",
    "# for key,value in y_tokenizer.word_counts.items():\n",
    "#     tot_cnt=tot_cnt+1\n",
    "#     tot_freq=tot_freq+value\n",
    "#     if(value<thresh):\n",
    "#         cnt=cnt+1\n",
    "#         freq=freq+value\n",
    "    \n",
    "# print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "# print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_train))\n",
    "\n",
    "y_train_seq = y_tokenizer.texts_to_sequences(y_train)\n",
    "y_test_seq = y_tokenizer.texts_to_sequences(y_test)\n",
    "\n",
    "y_train = pad_sequences(y_train_seq, maxlen=max_len_headline, padding='post')\n",
    "y_test = pad_sequences(y_test_seq, maxlen=max_len_headline, padding='post')\n",
    "y_voc_size = len(y_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3516, 3516)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_counts['eostok'], len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_inputs = Input(shape=(max_len_news,))\n",
    "# encoder_embedding = Embedding(news_vocab_size, 64)(encoder_inputs)\n",
    "# encoder_outputs, state_h, state_c = LSTM(64, return_state=True)(encoder_embedding)\n",
    "# encoder_states = [state_h, state_c]\n",
    "\n",
    "# # Build the decoder\n",
    "# decoder_inputs = Input(shape=(None,))\n",
    "# decoder_embedding = Embedding(y_voc_size, 64)(decoder_inputs)\n",
    "# decoder_lstm = LSTM(64, return_sequences=True, return_state=True)\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "# decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax'))\n",
    "# output = decoder_dense(decoder_outputs)\n",
    "\n",
    "# # Build and compile the model\n",
    "# model = Model([encoder_inputs, decoder_inputs], output)\n",
    "# model.summary()\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit([X_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:], batch_size=64, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 47)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 47, 100)      1946400     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 47, 300),    481200      ['embedding[0][0]']              \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 47, 300),    721200      ['lstm[0][0]']                   \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 100)    776200      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 47, 300),    721200      ['lstm_1[0][0]']                 \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 300),  481200      ['embedding_1[0][0]',            \n",
      "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " attention_layer (AttentionLaye  ((None, None, 300),  180300     ['lstm_2[0][0]',                 \n",
      " r)                              (None, None, 47))                'lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, None, 600)    0           ['lstm_3[0][0]',                 \n",
      "                                                                  'attention_layer[0][0]']        \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 7762)  4664962     ['concat_layer[0][0]']           \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,972,662\n",
      "Trainable params: 9,972,662\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "latent_dim=300\n",
    "emb_dim=100\n",
    "\n",
    "enc_inputs = Input(shape=(max_len_news,))\n",
    "embedding1 = Embedding(news_vocab_size,emb_dim, trainable=True)(enc_inputs)\n",
    "\n",
    "lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.3, recurrent_dropout=0.2)\n",
    "enc_output1, h1, c1 = lstm1(embedding1)\n",
    "\n",
    "lstm2 = LSTM(latent_dim, return_sequences=True,return_state=True, dropout=0.3, recurrent_dropout=0.2)\n",
    "enc_output2, h2, c2 = lstm2(enc_output1)\n",
    "\n",
    "lstm3 = LSTM(latent_dim, return_sequences=True,return_state=True, dropout=0.3, recurrent_dropout=0.2)\n",
    "enc_outputs, h3, c3 = lstm3(enc_output2)\n",
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(None, ))\n",
    "dec_embedding = Embedding(y_voc_size, emb_dim, trainable=True)\n",
    "dec_emb_out = dec_embedding(decoder_inputs)\n",
    "\n",
    "dec_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.3, recurrent_dropout=0.2)\n",
    "decoder_outputs, fwd_state, back_state = dec_lstm(dec_emb_out, initial_state = [h3, c3])\n",
    "\n",
    "\n",
    "\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_state = attn_layer([enc_outputs, decoder_outputs])\n",
    "\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "model = Model([enc_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy',mode='max',verbose=1,patience=40)\n",
    "rl = ReduceLROnPlateau(monitor='val_accuracy',mode='max',verbose=1,patience=5,factor=0.1,min_lr=0.001)\n",
    "mc = ModelCheckpoint('checkpoint/',monitor='val_accuracy',verbose=1,mode='max',save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 6.4889 - accuracy: 0.2007\n",
      "Epoch 1: val_accuracy improved from -inf to 0.32576, saving model to checkpoint\\\n",
      "INFO:tensorflow:Assets written to: checkpoint\\assets\n",
      "55/55 [==============================] - 45s 672ms/step - loss: 6.4889 - accuracy: 0.2007 - val_loss: 5.0628 - val_accuracy: 0.3258 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 5.8868 - accuracy: 0.2696\n",
      "Epoch 2: val_accuracy improved from 0.32576 to 0.35985, saving model to checkpoint\\\n",
      "INFO:tensorflow:Assets written to: checkpoint\\assets\n",
      "55/55 [==============================] - 36s 657ms/step - loss: 5.8868 - accuracy: 0.2696 - val_loss: 4.8986 - val_accuracy: 0.3598 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 5.6950 - accuracy: 0.2804\n",
      "Epoch 3: val_accuracy did not improve from 0.35985\n",
      "55/55 [==============================] - 30s 549ms/step - loss: 5.6950 - accuracy: 0.2804 - val_loss: 4.9104 - val_accuracy: 0.3503 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 5.5470 - accuracy: 0.2836\n",
      "Epoch 4: val_accuracy did not improve from 0.35985\n",
      "55/55 [==============================] - 30s 552ms/step - loss: 5.5470 - accuracy: 0.2836 - val_loss: 4.8724 - val_accuracy: 0.3507 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 5.4148 - accuracy: 0.2846\n",
      "Epoch 5: val_accuracy improved from 0.35985 to 0.36638, saving model to checkpoint\\\n",
      "INFO:tensorflow:Assets written to: checkpoint\\assets\n",
      "55/55 [==============================] - 37s 677ms/step - loss: 5.4148 - accuracy: 0.2846 - val_loss: 4.7854 - val_accuracy: 0.3664 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 5.2907 - accuracy: 0.2880\n",
      "Epoch 6: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 542ms/step - loss: 5.2907 - accuracy: 0.2880 - val_loss: 4.7668 - val_accuracy: 0.3575 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 5.1645 - accuracy: 0.2895\n",
      "Epoch 7: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 29s 534ms/step - loss: 5.1645 - accuracy: 0.2895 - val_loss: 4.7840 - val_accuracy: 0.3545 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 5.0394 - accuracy: 0.2920\n",
      "Epoch 8: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 552ms/step - loss: 5.0394 - accuracy: 0.2920 - val_loss: 4.7509 - val_accuracy: 0.3620 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.9141 - accuracy: 0.2938\n",
      "Epoch 9: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 544ms/step - loss: 4.9141 - accuracy: 0.2938 - val_loss: 4.8005 - val_accuracy: 0.3535 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.7922 - accuracy: 0.2976\n",
      "Epoch 10: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 542ms/step - loss: 4.7922 - accuracy: 0.2976 - val_loss: 4.8300 - val_accuracy: 0.3534 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.6702 - accuracy: 0.2987\n",
      "Epoch 11: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 549ms/step - loss: 4.6702 - accuracy: 0.2987 - val_loss: 4.8633 - val_accuracy: 0.3521 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.5360 - accuracy: 0.3021\n",
      "Epoch 12: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 29s 531ms/step - loss: 4.5360 - accuracy: 0.3021 - val_loss: 4.8386 - val_accuracy: 0.3613 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.4066 - accuracy: 0.3039\n",
      "Epoch 13: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 569ms/step - loss: 4.4066 - accuracy: 0.3039 - val_loss: 4.8782 - val_accuracy: 0.3534 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.2761 - accuracy: 0.3084\n",
      "Epoch 14: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 539ms/step - loss: 4.2761 - accuracy: 0.3084 - val_loss: 4.8855 - val_accuracy: 0.3557 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.1453 - accuracy: 0.3132\n",
      "Epoch 15: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 29s 536ms/step - loss: 4.1453 - accuracy: 0.3132 - val_loss: 4.9139 - val_accuracy: 0.3563 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.0136 - accuracy: 0.3174\n",
      "Epoch 16: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 32s 590ms/step - loss: 4.0136 - accuracy: 0.3174 - val_loss: 4.9506 - val_accuracy: 0.3501 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.8826 - accuracy: 0.3261\n",
      "Epoch 17: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 32s 576ms/step - loss: 3.8826 - accuracy: 0.3261 - val_loss: 4.9735 - val_accuracy: 0.3523 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.7567 - accuracy: 0.3340\n",
      "Epoch 18: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 547ms/step - loss: 3.7567 - accuracy: 0.3340 - val_loss: 4.9920 - val_accuracy: 0.3504 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.6294 - accuracy: 0.3441\n",
      "Epoch 19: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 569ms/step - loss: 3.6294 - accuracy: 0.3441 - val_loss: 5.0108 - val_accuracy: 0.3523 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.5027 - accuracy: 0.3563\n",
      "Epoch 20: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 554ms/step - loss: 3.5027 - accuracy: 0.3563 - val_loss: 5.0482 - val_accuracy: 0.3511 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.3751 - accuracy: 0.3699\n",
      "Epoch 21: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 553ms/step - loss: 3.3751 - accuracy: 0.3699 - val_loss: 5.0360 - val_accuracy: 0.3546 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.2597 - accuracy: 0.3848\n",
      "Epoch 22: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 572ms/step - loss: 3.2597 - accuracy: 0.3848 - val_loss: 5.0637 - val_accuracy: 0.3536 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.1434 - accuracy: 0.4028\n",
      "Epoch 23: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 539ms/step - loss: 3.1434 - accuracy: 0.4028 - val_loss: 5.0854 - val_accuracy: 0.3540 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.0204 - accuracy: 0.4200\n",
      "Epoch 24: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 562ms/step - loss: 3.0204 - accuracy: 0.4200 - val_loss: 5.1364 - val_accuracy: 0.3479 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.9024 - accuracy: 0.4374\n",
      "Epoch 25: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 557ms/step - loss: 2.9024 - accuracy: 0.4374 - val_loss: 5.1368 - val_accuracy: 0.3542 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.7963 - accuracy: 0.4556\n",
      "Epoch 26: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 545ms/step - loss: 2.7963 - accuracy: 0.4556 - val_loss: 5.2014 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.6797 - accuracy: 0.4748\n",
      "Epoch 27: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 32s 577ms/step - loss: 2.6797 - accuracy: 0.4748 - val_loss: 5.1942 - val_accuracy: 0.3522 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.5648 - accuracy: 0.4963\n",
      "Epoch 28: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 568ms/step - loss: 2.5648 - accuracy: 0.4963 - val_loss: 5.2305 - val_accuracy: 0.3485 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.4701 - accuracy: 0.5141\n",
      "Epoch 29: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 32s 582ms/step - loss: 2.4701 - accuracy: 0.5141 - val_loss: 5.2991 - val_accuracy: 0.3441 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.3590 - accuracy: 0.5385\n",
      "Epoch 30: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 557ms/step - loss: 2.3590 - accuracy: 0.5385 - val_loss: 5.3176 - val_accuracy: 0.3404 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.2686 - accuracy: 0.5541\n",
      "Epoch 31: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 561ms/step - loss: 2.2686 - accuracy: 0.5541 - val_loss: 5.3172 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.1591 - accuracy: 0.5742\n",
      "Epoch 32: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 32s 577ms/step - loss: 2.1591 - accuracy: 0.5742 - val_loss: 5.3931 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.0772 - accuracy: 0.5880\n",
      "Epoch 33: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 551ms/step - loss: 2.0772 - accuracy: 0.5880 - val_loss: 5.3686 - val_accuracy: 0.3454 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.9756 - accuracy: 0.6128\n",
      "Epoch 34: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 558ms/step - loss: 1.9756 - accuracy: 0.6128 - val_loss: 5.4104 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.8884 - accuracy: 0.6299\n",
      "Epoch 35: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 554ms/step - loss: 1.8884 - accuracy: 0.6299 - val_loss: 5.4541 - val_accuracy: 0.3445 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.8052 - accuracy: 0.6479\n",
      "Epoch 36: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 32s 576ms/step - loss: 1.8052 - accuracy: 0.6479 - val_loss: 5.4652 - val_accuracy: 0.3442 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.7175 - accuracy: 0.6661\n",
      "Epoch 37: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 557ms/step - loss: 1.7175 - accuracy: 0.6661 - val_loss: 5.5206 - val_accuracy: 0.3414 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.6428 - accuracy: 0.6788\n",
      "Epoch 38: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 547ms/step - loss: 1.6428 - accuracy: 0.6788 - val_loss: 5.5101 - val_accuracy: 0.3433 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.5697 - accuracy: 0.6970\n",
      "Epoch 39: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 543ms/step - loss: 1.5697 - accuracy: 0.6970 - val_loss: 5.5514 - val_accuracy: 0.3445 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.4901 - accuracy: 0.7140\n",
      "Epoch 40: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 566ms/step - loss: 1.4901 - accuracy: 0.7140 - val_loss: 5.5668 - val_accuracy: 0.3427 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.4207 - accuracy: 0.7274\n",
      "Epoch 41: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 556ms/step - loss: 1.4207 - accuracy: 0.7274 - val_loss: 5.5846 - val_accuracy: 0.3439 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.3556 - accuracy: 0.7412\n",
      "Epoch 42: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 571ms/step - loss: 1.3556 - accuracy: 0.7412 - val_loss: 5.6107 - val_accuracy: 0.3438 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.2813 - accuracy: 0.7564\n",
      "Epoch 43: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 558ms/step - loss: 1.2813 - accuracy: 0.7564 - val_loss: 5.6688 - val_accuracy: 0.3410 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.2101 - accuracy: 0.7709\n",
      "Epoch 44: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 568ms/step - loss: 1.2101 - accuracy: 0.7709 - val_loss: 5.6452 - val_accuracy: 0.3443 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.1608 - accuracy: 0.7839\n",
      "Epoch 45: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 548ms/step - loss: 1.1608 - accuracy: 0.7839 - val_loss: 5.6883 - val_accuracy: 0.3441 - lr: 0.0010\n",
      "Epoch 45: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history=model.fit([X_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,epochs=50,batch_size=64, callbacks=[es, rl, mc], validation_data=([X_test,y_test[:,:-1]], y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABKA0lEQVR4nO3dd3hUZf7+8feZSe+ENEICJBB6b0oHRRAVURcLYmHtCihrXddd29cfrG0VRVF0xQZiodoQdKX33nsCoYZQUkmd+f1xIIgCJjDJmZncr+s61yRTP8m54Nw553k+j+F0Op2IiIiIuIDN6gJERETEeyhYiIiIiMsoWIiIiIjLKFiIiIiIyyhYiIiIiMsoWIiIiIjLKFiIiIiIyyhYiIiIiMv4VPUHOhwO9u/fT2hoKIZhVPXHi4iIyAVwOp3k5OQQHx+PzXbu8xJVHiz2799PYmJiVX+siIiIuEB6ejoJCQnnfLzKg0VoaChgFhYWFlbVHy8iIiIXIDs7m8TExLLj+LlUebA4dfkjLCxMwUJERMTD/NkwBg3eFBEREZdRsBARERGXUbAQERERl6nyMRYiIiKVwel0UlJSQmlpqdWleCS73Y6Pj89Ft4JQsBAREY9XVFTEgQMHyM/Pt7oUjxYUFEStWrXw8/O74PdQsBAREY/mcDhITU3FbrcTHx+Pn5+fGjBWkNPppKioiMOHD5OamkpKSsp5m2Cdj4KFiIh4tKKiIhwOB4mJiQQFBVldjscKDAzE19eX3bt3U1RUREBAwAW9jwZvioiIV7jQv7DlNFf8DrUXRERExGUULERERMRlFCxERES8QL169XjzzTetLkODN0VERKzSs2dPWrdu7ZJAsHz5coKDgy++qIvkFWcsCopL+WhBKg9+vpKSUofV5YiIiLjEqaZf5REdHe0Ws2K8Ilj42m289b/t/LjhIGv3Hre6HBERsZjT6SS/qKTKN6fTWe4ahwwZwty5cxk9ejSGYWAYBh9//DGGYfDTTz/Rvn17/P39mT9/Pjt37mTAgAHExsYSEhJChw4d+Pnnn894v99fCjEMgw8//JDrr7+eoKAgUlJSmDFjhqt+xefkFZdC7DaDLvWj+H79AeZvz6Rd3UirSxIREQudKC6l6bM/VfnnbnqxL0F+5Tu0jh49mm3bttG8eXNefPFFADZu3AjAk08+yWuvvUZycjIRERHs3buXq666ipdeeomAgAA++eQT+vfvz9atW6lTp845P+OFF17glVde4dVXX+Xtt99m8ODB7N69m8jIyjtOesUZC4BuKVEALNieaXElIiIify48PBw/Pz+CgoKIi4sjLi4Ou90OwIsvvsgVV1xB/fr1qVmzJq1ateL++++nRYsWpKSk8NJLL5GcnPynZyCGDBnCoEGDaNCgASNHjiQvL49ly5ZV6s/lFWcsALqeDBar04+TU1BMaICvxRWJiIhVAn3tbHqxryWf6wrt27c/4/u8vDxeeOEFvvvuO/bv309JSQknTpxgz549532fli1bln0dHBxMaGgoGRkZLqnxXLwmWCTUCCIpKpjUzDyW7DrKFU1jrS5JREQsYhhGuS9JuKPfz+544okn+Omnn3jttddo0KABgYGBDBw4kKKiovO+j6/vmX9kG4aBw1G5kxy85lIIQNcGpy6HHLa4EhERkT/n5+dXrmXe58+fz5AhQ7j++utp0aIFcXFxpKWlVX6BF8C7gsXJyyHzd2ichYiIuL969eqxdOlS0tLSyMzMPOfZhAYNGjBlyhTWrFnD2rVrufXWWyv9zMOF8qpg0al+Tew2g12H89h3/ITV5YiIiJzX448/jt1up2nTpkRHR59zzMQbb7xBjRo16Ny5M/3796dv3760bdu2iqstH8NZkUm3LpCdnU14eDhZWVmEhYW5/P1veHchq/Yc5+W/tODmDueegiMiIt6hoKCA1NRUkpKSLnipbzGd73dZ3uO3V52xAOiaEg3AfE07FRERqXJeFyxO9bNYtPMIDkeVnowRERGp9rwuWLROjCDE34ejeUVsOpBtdTkiIiLVitcFC1+7jUuTawK6HCIiIlLVvC5YwG/ae+9QPwsREZGq5JXB4lQ/i+Vpxygo/vPGIyIiIuIaXhkskqOCiQ8PoKjEwbLUo1aXIyIiUm14ZbAwDON0F0619xYREakyXhksQP0sRERErOC1waJLfXNmyJaDORzOKbS4GhERkT/q2bMnI0aMcNn7DRkyhOuuu85l73chvDZY1Azxp1m82XJ0oRYlExERqRJeGyzgN6ud6nKIiIi4mSFDhjB37lxGjx6NYRgYhkFaWhqbNm3iqquuIiQkhNjYWG6//XYyM08fx7755htatGhBYGAgNWvWpHfv3uTl5fH888/zySefMH369LL3mzNnTpX/XF4dLLo1MMdZLNhxmCpea01ERKzkdEJRXtVvFTjWjB49mk6dOnHvvfdy4MABDhw4gK+vLz169KB169asWLGCmTNncujQIW666SYADhw4wKBBg7jrrrvYvHkzc+bM4YYbbsDpdPL4449z0003ceWVV5a9X+fOnSvrN3xOPlX+iVWofb0a+PvYOJRdyI6MXFJiQ60uSUREqkJxPoyMr/rP/cd+8Asu11PDw8Px8/MjKCiIuLg4AJ599lnatm3LyJEjy5730UcfkZiYyLZt28jNzaWkpIQbbriBunXrAtCiRYuy5wYGBlJYWFj2flbw6jMWAb52OiZFArocIiIi7m/lypX8+uuvhISElG2NGzcGYOfOnbRq1YrLL7+cFi1acOONN/LBBx9w7Ngxi6s+k1efsQCzvff87Zks2JHJXV2TrC5HRESqgm+QefbAis+9CA6Hg/79+/Pyyy//4bFatWpht9uZPXs2ixYtYtasWbz99ts888wzLF26lKQk9zjGeX2w6NogGtjCkl1HKCpx4Ofj1SdpREQEwDDKfUnCSn5+fpSWnl56om3btkyePJl69erh43P2Q7RhGHTp0oUuXbrw7LPPUrduXaZOncqjjz76h/ezgtcfZRvHhRIV4kd+USmr9rjX6SIREane6tWrx9KlS0lLSyMzM5OhQ4dy9OhRBg0axLJly9i1axezZs3irrvuorS0lKVLlzJy5EhWrFjBnj17mDJlCocPH6ZJkyZl77du3Tq2bt1KZmYmxcXFVf4zVThY7Nu3j9tuu42aNWsSFBRE69atWblyZWXU5hI2m0GXBidXO9U4CxERcSOPP/44drudpk2bEh0dTVFREQsXLqS0tJS+ffvSvHlzHnnkEcLDw7HZbISFhTFv3jyuuuoqGjZsyD//+U9ef/11+vXrB8C9995Lo0aNaN++PdHR0SxcuLDKf6YKXQo5duwYXbp0oVevXvz444/ExMSwc+dOIiIiKqk81+jaIIrpa/Yzf0cmj/dtZHU5IiIiADRs2JDFixf/4f4pU6ac9flNmjRh5syZ53y/6OhoZs2a5bL6LkSFgsXLL79MYmIi48ePL7uvXr16rq7J5bqdXDdk/d7jZOUXEx7ka3FFIiIi3qlCl0JmzJhB+/btufHGG4mJiaFNmzZ88MEH531NYWEh2dnZZ2xVLS48gAYxITicsGinLoeIiIhUlgoFi127djF27FhSUlL46aefeOCBB3j44Yf59NNPz/maUaNGER4eXrYlJiZedNEXouvJcRbztW6IiIhIpalQsHA4HGUdwdq0acP999/Pvffey9ixY8/5mqeffpqsrKyyLT09/aKLvhDdUjSAU0REpLJVKFjUqlWLpk2bnnFfkyZN2LNnzzlf4+/vT1hY2BmbFS5JromPzWDP0Xx2H8mzpAYRERFvV6Fg0aVLF7Zu3XrGfdu2bSvrV+7OQvx9aFu3BqD23iIi3kiLTV48V/wOKxQs/va3v7FkyRJGjhzJjh07mDhxIuPGjWPo0KEXXUhV6KZ+FiIiXsfX15zpl5+fb3Elnu/U7/DU7/RCVGi6aYcOHZg6dSpPP/00L774IklJSbz55psMHjz4gguoSl1Tonh99jYW7cyk1OHEbjOsLklERC6S3W4nIiKCjIwMAIKCgjAM/f9eEU6nk/z8fDIyMoiIiMBut1/we1V4rZBrrrmGa6655oI/0EotEyIIC/Ahu6CEdXuP06ZODatLEhERFzi1TPipcCEXJiIi4qKXXPf6Rch+y24z6JYSzffrD/B/321i4r2XEuB74alMRETcg2EY1KpVi5iYGEvWx/AGvr6+F3Wm4pRqFSwAHuvTkPnbD7Nqz3Ge/GYdo29prVNmIiJewm63u+TgKBfO61c3/b3k6BDeu60dPjaDGWv3M/qX7VaXJCIi4jWqXbAA6Nwgipeuaw7Amz9vZ/qafRZXJCIi4h2qZbAAuKVjHe7rngzAE9+sY+XuoxZXJCIi4vmqbbAAeOrKxlzRNJaiEgf3fbqS9KOaAy0iInIxqnWwsNsMRt/SmmbxYRzJK+Kuj5eTXaDRxCIiIheqWgcLgCA/H/57Zwdiw/zZnpHL0AmrKCl1WF2WiIiIR6r2wQIgLjyAD+/oQKCvnfnbM3nh203qOS8iInIBFCxOapEQzhs3t8Yw4LMlu/l4UZrVJYmIiHgcBYvfuLJ5HE9d2RiA//tuE79uUWtYERGRilCw+J37uydzU/sEHE4YNnEVm/ZnW12SiIhI+ZQUwcENlpagYPE7hmHw0nUt6JRck7yiUm79cAmr9hyzuiwREZE/cjrh0EZY/A5MuBFergcf9IIi69onVLu1QsrDz8fGe7e1487xy1iTfpzBHyzl3dva0qtRjNWliYiINzi4AdZ/BbvmQGAk1GwANetDZH3zNqIO2H3P/trj6ebrds2B1LmQd/jMx4NqwrFUiG1WyT/E2RnOKp7+kJ2dTXh4OFlZWYSFhVXlR1dYflEJD3y+innbDuNjM3jtxlZc16a21WWJiIgnytoL67+GdV9DxsbzP9ewQ426p4NGjXqQud0ME0d3nvlc3yCo2xmSe5pbTDOwuf6CRHmP3woWf6KoxMET36xl+pr9APzz6ibc0y3Z4qpERMQjnDgGm6abYWL3gtP32/0gpQ80vQ5KTsCRnWZgOLILju4y7zsXww61254OEgkdwMe/kn+Q8h+/dSnkT/j52HjjptbUDPbno4WpvPT9ZjJzi3jqykZabl1ERP4o/yikLYB1X8L2WVBadPqxul2h5Y3QdAAE1jj76x0OyDlwMmicDBzH0iC0FiT3gnpdICC8Sn6UC6FgUQ42m8G/rmlCVKgfr8zcyntzd3I0r5CR17fAx67xryIi1Y7TaR78D281t8ytcHibefv7MQ8xTaHlTdB8IEQk/vl722wQXtvckrpXTv2VSMGinAzD4KGeDagZ7MfTU9bz1Yq9HM0rZsytbQjwtVtdnoiIuFphrhkesvZC9n5zO7rLDA+Z26HwPO0IatSDJtdCy5shrnmVlewOFCwq6OYOdagR5MfwL1bz8+ZD3PHfZXxwZ3vCA88xeldERNxLabF5ViH3EORmQM5BM0Bk7zsdILL3QUHW+d/HsENkEkQ1guiTW1RDc/MPqZqfxQ1p8OYFWpZ6lLs/WU5OQQmN40L55K6OxIYFWF2WiIiUlsDBtZC+3AwIuRmnQ0TuQcg/Uv738g+DsPjTW3id0yEiMrlKBk26C80KqQKbD2Rz50fLyMgpJD48gHF3tKd5bfcdUCMi4pUcDji0HlLnQep82LP4/JcpAGw+EBwDITEQEgthtSCs9m9CRG1zsGSAZx+nXEnBooqkH83nzo+WsSszjwBfG68MbMW1reKtLktExHMUZMHWH82xDAHhEBABgRHmbUD4ya/DT58dcDjg8GYzRKTNN2dgFBw/8z39w83eDpHJp8NDaKx5GxJrNqWqhF4P3kzBogplnSjmkUmrmbPVHAn8YM/6PN6nEXabpqOKiJxVYS5smwkbpsCO2WdOyTwXn0AzYJQWmv0hfssvFOp2gnrdIKkbxLUEmwbWu5KCRRUrdTh55actvD93FwCXNY7hzVtaExagQZ0iIgAUnzD7OmyYDNtmndkEKqoR1G4HRTlw4rh5FqPg1G028LtDlW8Q1Ln0ZJDoDrVag13zESqTgoVFpq/Zx5PfrKOwxEFydDAf3tGe5OjqOzpYRKq5kkLY8QtsnGJe7ijKPf1YZDI0uwGa32D2ejhX00FHKRTmnA4aTofZttrHr0p+BDEpWFho/d4s7vtsBQeyCggN8OGtQW20gJmIeI/8o7B3hTll88Qx84B/4ph5puH33xccN4PAKeF1oNl10PwvUKvVucOEuB0FC4sdzinkwc9XsmL3MQwDnrqyMfd3T1YbcBHxPCWFkL4Mdv0KO3+F/av5w6WJ8wmtBc2uN89OJLRXmPBQChZuoKjEwXMzNvDFsnQABrSO5+W/tFSnThFxb04nZGwyQ8SuX2H3IijOP/M5NVPM1TcDIsw1LwJP3p7t+5BYzcDwAlqEzA34+dgYeX0LmtYK44VvNzF9zX52Hs5l7OB2JEYGWV2eiMhpx9NP9oGYay7NnXvozMeDY8yVNOv3gqQe5joWImehMxZVZPHOIwyduIqjeUWEB/ryn5tacXmTWKvLEhFPVZQPm78FRwlEpUDNBhAUWf7X5xwye0CkzjX7QRxLPfNxn0CzD0T9XuaKmrHNdAmjmtOlEDe07/gJHpqwirXpxwF4oEd9Hu/TUCukikj55R+F5f+FpWP/2Jo6MNIMGKeCxqmvaySZlzLSFphnJdLmw+EtZ77WsEPttub0zfq9IPGSatWuWv6cgoWbKipxMPKHzXy8KA2AjkmRjBnUhhitMyIi55O1D5a8CyvGQ3GeeV9EHXMVzSM7zTUxzunUmQbnmffFtTB7QCR1hzqd1L5azkvBws19v+4AT36zlryiUqJC/HlrUGs614+yuiwRcTeHt8LCt2Ddl+AoNu+LbQ5dRpgzLU41hSrKMwPGkR2nt8zt5u2pdTOiG5shol43qNe1YpdOpNpTsPAAOw/n8tDnq9h6KAebAY/1acSDPepjUytwEUlfDgvfhC3fnb6vblfoOgIa9C7/eAen0+w3YdggWH+8yIVTsPAQJ4pK+ee0DUxetReAXo2i+c9NrakRrI5yIh6rKM+8dJGVbl6iyNoH2Xsh7winL0cYvwkHJ29PfZ97CPYuP/1+ja8xz1Akdqia+kXOQsHCgzidTr5akc6z0zdSWOKgdkQg7wxuS+vECKtLE5HzKT4BG6eZISBr78kQsfePK21eCJsvtLwZujwM0Y0u/v1ELpKChQfauD+LhyasYveRfHztBv+6pim3X1pX3TpF3M2x3bDiI1j1KZw4evbn+IdBWG2z30NYbQhPgOBoc8XNsv92T97+/nubD9S/XL0ixK0oWHio7IJinvx6HTM3HgTg+ja1+X/XNyfIT73MRCzldJqNo5Z9ANt+PL3+RXgdcxGtGvUgPPF0kNAMC/EyChYezOl08uH8VP49cwulDieNYkN57/Z2JEUFW12aSPVTkA1rJ8GycXBk++n7k3tBx/ugYV/zLISIl1Ow8AJLdh1h2MTVZOYWEurvw2s3taJvsziryxLxfg4HZGyElZ/A2i9OL/XtFwqtb4UO90B0Q2trFKliChZe4lB2AUMnrGLF7mOAunWKVIqCbNi3wpzimb7U/Log6/TjUY2g473Q6hbwD7WuThELKVh4keJSB6N+2MJHC81e/p2Sa/L2rW2IClG7XRHAHEyZvgx8/MA3GPyCwC/49Ne+J7+3+5pjJY7sMANE+jJzRkfGZv6wDLhPIDS43AwUST20ToZUewoWXujbtft5avI68otKiQsL4J3BbWlXt4bVZYlYo7QYtv4AKz82l/f+fTA4G7ufOePi90uAA0TUhcSOkNDR7BcR29wMIiICKFh4re2Hcnjg85XsPJyHr93gn1c35Y5OmpIq1cjRXeY0z9UTIC/j9P21258MDXnmyp/F+WajqqI8cJae+R4+ARDfBhI6mIttJXSAUK02LHI+ChZeLLewhCe/WcsP680pqQNaxzPy+hYE+2tKqnipkkLY8r15diJ17un7Q2Kh9WBoeztEJp/9tU4nlBaZAaM433yv8ETzsomIlJuChZdzOp38d0Eqo340p6SmxIQw9ra2NIjRwDJxcw4HHFxrLvld9r+P8xxNo5yweyGsmfibJcINc+xDuyHQ8EpdrhCpIgoW1cTytKMMnbCKjJxCgvzsvPyXlvRvFW91WSJnKimCtHnmWYctP0DuwYq/R2gtaHO7eXYioo7raxSR81KwqEYO5xTy8BerWbzL/ItuSOd6/OOqJvj5aEqqWKgwB3b8DJu/g+2zTi/dDWY/iMh6nHshrt98HVrLvNyR0uf0EuEiUuUULKqZklIH/5m9jXfn7ASgTZ0I3rm1LfERgRZXJtVKbgZs/dE8M7FrDpQWnn4sJBYaXWWu1JnUDXw0XVrEk1TPYOF0Vvu55r9sPsTfvlxDdkEJkcF+jL6lNd1Soq0uS7yFo9RcwfNY2tm3snEQJ0Umm0GiSf+TszZ0Fk3EU1W/YLH0fUidBzd+XO0Hc6UfzefBCSvZsC8bw4ARlzdk+GUNsNmqd+iSCijIhsNbIGMTZGyBzK1mcDieDo7i8782vg00vhoa9zeX+67mYV/EW1RKsHj++ed54YUXzrgvNjaWgwfLPxCrUoJF1l54ux2UFJh/GQ0cX+3DRUFxKS98u5EvlqUD0L1hNG/e3JrIYE2x80qlxXBwvdlNcu9y8/ugSAiqCYGR5teBJ78PioTAGhAQYf6bydxqdp787Za999yfZfOFGnXN1Tx/v0XU1aqeIl6qvMfvCo+EatasGT///HPZ93a7G6zqF54AN0+ASYNg87cw+W74y3+rdbgI8LUz6oaWtKsbyT+nrWfetsNc89Z83r2tHa0TI6wuTy5WQdbJdS2WwJ4lsG/l2btJno9hOz2l82xCa0FME4hpClENzcsakUnm/VrNU0TOocLBwsfHh7g4N1xhM6W3GS6+HAybppv/ad7wYbUfRT6wXQLN4sN4aMIqUjPzuPG9RTx7TVNuu1TdOj1CaTHkHICsfXAs1TwbsWepeYni94EgINzsIpnYEfzD4cRRyD968vbIb74+BkU54HSYrwuqaYaHmCbmFt0EYhqbZzVERCqowkfd7du3Ex8fj7+/P5dccgkjR44kOfkcHe+AwsJCCgtPjwzPzs4+53MvWsM+cNNn8OVtsHEqGHa4/v1qHy6a1Apj+rAuPPn1OmZuPMi/pm9k5e5jjLyhBUF+1ft3Yymn0zzYZ6WbAyKz9p65Ze8zQ8WpAPB7NZKgzqVmmKhzqbkCZ3kHR5YUwoljZgvs4CjX/UwiUu1VaIzFjz/+SH5+Pg0bNuTQoUO89NJLbNmyhY0bN1KzZs2zvuZs4zKAyp1uuuV7+OoOcJRAi5vg+vd06hazW+eH81P590yzW2fD2BDG3taO+tEhVpfmnQqyzwwM2fvMMw/Ze0/e7jPHOPwZmy+E1zbbUNdqdfKsxCVa20JEqlSVzArJy8ujfv36PPnkkzz66KNnfc7ZzlgkJiZWfh+Lzd/C10PMcNHyFrjuXYWLk5buOsKwL1ZzOKeQYD87r97Yiqta1LK6LM/jdJqXGI7uOvt24lj53ic4xhwndCo8hCdA2G++Do7WNE0RsVyVTTe94ooraNCgAWPHjnVpYS6xaTp8/VdzZcNWt8KAMQoXJ2XkFDBs4mqWpR4F4K4uSTx9VWN87TqAndWJ47BvBexdAYe3ngwPqVCYdf7XBYRD2KnQcCownLqtbd6qUZSIeIBKmxXyW4WFhWzevJlu3bpdzNtUnqYDYOB/4Zu7Ye1Ec0DntW/rrz8gJjSAifdcwquztvL+3F18tDCVdXuPM+bWtsSFB1hdnrWcTjiy05y6eWr6ZsZmzjl7IizBnC0RmXzmVqMu+GtROBGpXip0xuLxxx+nf//+1KlTh4yMDF566SXmzp3L+vXrqVu3brnew5KW3hsmw+R7zEFwbe+Aa0aXL1xUk06eP208yONfrSWnsISoED/euqUNnRtUowF9J47BwQ2wd9nJKZxLzdkTv1cjyRzbENccIuufDg++apsuIt6vUs5Y7N27l0GDBpGZmUl0dDSXXnopS5YsKXeosEzzv5ghYcq9sOpTsy1xUg/z4HHi2OlpeGVfHzO3wmyo2cAccV+nk7lFJntd2OjbLI5Gw0N54POVbDmYw23/XcrfejfkoV4NsHtTt87ik82gDm2CjI0nbzdDzv4/PtfuD7XbmlM3Ey+BhA4QElP1NYuIeBjvaeldHuu+gqn3n3v6XnkER5+c4ncybNRq6TWNuE4UlfKv6Rv4ZqXZdbFbShRv3NyaqBA3HANQWgLFeVCUB0X55/g6zxxcmbHJDBFHd55734fXORkkTs64iGsBPupSKiJySvVbK6S8Nk2HJe+ZYeBUm+PAGmf/2jcQDm2APYtPdzcsLTrz/XyDoHY7s5V4uyFeMRDv6xXp/Gv6BgqKHcSE+jP6ljZ0qn/26cTlUlps9ku40DM9Tqc5WDJtAexeZG5Zey7svQJrQEwzsxFUbNPTX6sNtYjIeSlYVIaSQti/5nTQSF9y5pTC8DrQ6x/Q8iaPn32y7VAOQyesYntGLjYD/ta7IUN7lWMhs6I8c82K/ath3yrz9sh2c3ZEzRSISjEvL0WlmN9HJoPv7waLOhzmJYvfBoncc6xHY9jBL9jcfIPALwj8Qk5+HWwGhqhGp0NEaJzXXcoSEakKChZVweGAzG2w61dYONrskghme+TLn4OGfT36IJZfVMKz0zee+9JISaF5Rmf/ati32rw9vLmCl5oMiKhjBo3I+mbTqN2L/jh40u5nLrtdt7O51WplBggff4/+HYuIeAoFi6pWlA/L3ocFb5gLRIE5BqP3C1DnEmtru0hfr0jnjekLSS5No33AfgbXyyY6b4e5rPbZltAOiYX4tuaYhfg2ENvcHOtwZDtk7jBvj+wwvz5XHwifQHPgZN0uUK+LeblJsy9ERCyjYGGVE8fMcLH0/dPtmhtdBZc/a17Ld3elJSdnTmw0L2kc2mB+nXvo7M8PjDwdIOLbmIEirJxdPJ1OyDsMmdtPho2d5hiIel2hVmsNnhQRcSMKFlbL2gdz/w2rPzcvDRg2aDUIuj5qNlNy1RiMkqKLPwAXZMGOX2DrD7B91ukzLmcwcEQms74kkZ+PRLHZWZfQuq145ta+RIVW84ZaIiLVgIKFuzi8Df73orl2ySk2Hwit9bvWzgmn14sIS4DACMjLNHssZB/4ze0ByN5/8vaAeSkhtNZvzhic3P5sxcrje2DrTDNMpC0485KGf5h5+SK2mdkMKra5ebbFLxj446yRtwa14dLki5g1IiIibk/Bwt3sXQG/vGgexJ2llf954XUgvvXpoFGrFRzfDVt/NMPEwfVnPj+qITTqZ162Sejwp2dUfj9r5NErGvJQz3LMGhEREY+kYOGuSkvM8QrZ+yAr/fTy2b9dVjsvw3yuYTNXvgyrBaHxJ29rQVj86dugmuYYhf2rT29Htv95HYbNbPJ1KkxENajwj5JfVMK/pm1k8ioPaKglIiIXRcHCk5UUmqtpBtUE+wWsE1eQBQfW/SZsrIJjaeAbDA0ug0ZXQ0ofCHbN5YvfXhqJDfPnrVvacIkujYiIeBUFCzlTQRb4BFRaZ9Bth3J4aMIqdpy8NPJYn0Y82KO+Lo2IiHiJ8h6/tX54dREQXqntxhvGhjJjWBduaFsbhxNe/Wkrd45fxpHcwkr7TBERcT8KFuIyQX4+/Oem1rw6sCUBvjbmb8/kqrfms3TXEatLExGRKqJgIS53Y/tEpg/tSv3oYA5lFzLogyWMm7eTKr7qJiIiFlCwkErRKC6UGcO6ckMb89LIyB+28NhXaykoroKptiIiYhkFC6k0wf4+vH5TK164thl2m8GU1fsY9MESMnIKrC5NREQqiYKFVCrDMLizcz0++WtHwgJ8WL3nOAPGLGTDvnMsPiYiIh5NwUKqRNeUKKYP60pydDAHsgoY+N4ivl93wOqyRETExRQspMokRQUz9aEu9GgYTUGxg6ETV/Gf2dtwODSoU0TEWyhYSJUKD/TloyEduKdrEgBv/bKdoRNXkV9UYnFlIiLiCgoWUuXsNoN/XtOUVwa2xM9u48cNBxk4djH7jp+wujQREblIChZimZvaJ/LFfZcQFeLHpgPZDBizgBVpR60uS0RELoKChViqXd1Ipg/rSpNaYWTmFjHogyVMWLpbzbRERDyUgoVYrnZEIJMf7MRVLeIoLnXyzNQNPD1lPYUlaqYlIuJpFCzELQT5+fDOrW156srG2AyYtDydm99fwoEsjbsQEfEkChbiNgzD4MGe9fn4rx0JD/RlTfpx+r+9QIuYiYh4EAULcTvdG0bz7bCuNI4LJTO3iMEfLuWTRWkadyEi4gEULMQt1akZxJSHOnNtq3hKHE6em7GRx77WImYiIu5OwULcVpCfD6Nvac0/r26CzYApq/Yx8L1F6nchIuLGFCzErRmGwT3dkvn87kuoEeTLhn3Z9H97AYt2ZFpdmoiInIWChXiEzg2i+HZ4V5rFh3E0r4jbP1rGfxekatyFiIibUbAQj5FQI4jJD3bmhja1KXU4+b/vNvHoVxp3ISLiThQsxKME+Np5/aZWPHtNU+w2g6mrNe5CRMSdKFiIxzEMg7u6JvHZ3R3Lxl1c+/YClqjfhYiI5RQsxGN1rh/FjGFdaVorjCN5RdymfhciIpZTsBCPlhhpjrsY0Pp0v4snvlmncRciIhZRsBCPF+hn582bW/PMVWa/i29W7uXm9xdrnREREQsoWIhXMAyDe7sn8+ldlxAR5MvavVn0f3sBy9OOWl2aiEi1omAhXqVrShQzhp5eZ2TQuCV8tmS3xl2IiFQRBQvxOqfWGbm6ZS1KHE7+NW0D/5i6nsISjbsQEalsChbilYL8fBgzqA1PXdkYw4AvlqUzaNwSMrILrC5NRMSrKViI1zIMgwd71mf8kA6EBfiwas9x+o9ZwOo9x6wuTUTEaylYiNfr2SiG6cO6khITwqHsQm5+fwlfrUi3uiwREa+kYCHVQlJUMFOHdqFP01iKSh08+c06npu+geJSh9WliYh4FQULqTZC/H1477Z2PHpFQwA+WbybwR8uJTO30OLKRES8h4KFVCs2m8HDl6fwwR3tCfH3YVnqUa59ewHr92ZZXZqIiFdQsJBq6YqmsUwb2pmkqGD2ZxUw8L1FTFu9z+qyREQ8noKFVFsNYkKZNrQLvRpFU1jiYMSXaxj5w2ZKHWqmJSJyoRQspFoLD/Tlwzs7MLRXfQDGzdvFkPHLyMovtrgyERHPpGAh1Z7dZvBE38a8c2tbAn3tzN+eyYB3FrD9UI7VpYmIeBwFC5GTrm5Zi8kPdqZ2RCBpR/K57p2FzNp40OqyREQ8ioKFyG80jQ/j2+Fd6ZRck7yiUu77bCWjf96OQ+MuRETK5aKCxahRozAMgxEjRrioHBHrRQb78endHRnSuR4Ab/y8jYcmrCKvsMTawkREPMAFB4vly5czbtw4WrZs6cp6RNyCr93G89c245WBLfGz25i58SA3vLuIPUfyrS5NRMStXVCwyM3NZfDgwXzwwQfUqFHD1TWJuI2b2icy6f5LiQn1Z+uhHK59ZwELtmdaXZaIiNu6oGAxdOhQrr76anr37v2nzy0sLCQ7O/uMTcSTtK1Tg2+Hd6V1YgTH84u546OlfDh/F06nxl2IiPxehYPFpEmTWLlyJaNGjSrX80eNGkV4eHjZlpiYWOEiRawWGxbApPsuZWC7BBxOeOn7zTz21VoKikutLk1ExK1UKFikp6fzyCOPMGHCBAICAsr1mqeffpqsrKyyLT1dy1WLZwrwtfPqwJY8378pdpvBlNX7uPG9xew/fsLq0kRE3IbhrMD53GnTpnH99ddjt9vL7istLcUwDGw2G4WFhWc8djbZ2dmEh4eTlZVFWFjYhVcuYqFFOzMZOmEVx/KLqRnsx9jb2tExKdLqskREKk15j98VChY5OTns3r37jPv++te/0rhxY5566imaN2/ussJE3F360Xzu/2wlmw5k42MzeO7aZtx2SR0Mw7C6NBERlyvv8dunIm8aGhr6h/AQHBxMzZo1yxUqRLxJYmQQkx/szJOT1/Ht2v38a9oGNu7L4oUBzfD3Of+ZOxERb6XOmyIXIdDPzlu3tObv/RpjGDBpeTqDxi0hI7vA6tJERCxRoUshrqBLIeKt5mzN4OEvVpNdUEJMqD/v396ONnXU50VEvEN5j986YyHiIj0bxTBjWFdSYkLIyCnk5veX8PmS3ep3ISLVioKFiAvViwpm6tAu9G0WS1Gpg39O28BjX6/lRJH6XYhI9aBgIeJiIf4+vHdbO57u1xibAVNW7eP6dxeSlplndWkiIpVOwUKkEhiGwf096jPhnkuJCvFjy8Ec+r+9gFkbD1pdmohIpVKwEKlEnerX5PuHu9G+bg1yCku477OVvDxzCyWlDqtLExGpFAoWIpUsNiyAL+67lLu6JAEwds5Obv/vMg7nFFpcmYiI6ylYiFQBX7uNZ/s3ZcytbQj2s7N41xGueXs+K3cftbo0ERGXUrAQqULXtIxn+rAuNIgJ4VC2OSV1/MJUTUkVEa+hYCFSxRrEhDJ9aBeuaVmLEoeTF77dxCOT1pBfVGJ1aSIiF03BQsQCwf4+vD2oDc/1b4qPzWDG2v1c/84iUjUlVUQ8nIKFiEUMw+CvXZL44r5LiQ71Z+uhHK59ewGzNx2yujQRkQumYCFisQ71Ivl+eFc61DOnpN776Qpe+2krpQ6NuxARz6NgIeIGYsICmHjvpfy1Sz0Axvy6gyHjl3Esr8jawkREKkjBQsRN+NptPNe/GaNvaU2gr5352zO55u0FrN+bZXVpIiLlpmAh4mYGtK7N1KGdqVcziH3HT/CX9xbx5fI9VpclIlIuChYibqhxXBgzhneld5NYikocPDV5PU9PWUdBsVZJFRH3pmAh4qbCAnwZd3s7nujbCMOAL5alc9P7i9l7LN/q0kREzknBQsSN2WwGQ3s14JO/diQiyJd1e7Po//YC5m07bHVpIiJnpWAh4gG6N4zmu+FdaZkQzrH8Yu4cv4wx/9uOQ1NSRcTNKFiIeIiEGkF8dX8nBnVMxOmE12Zt477PVpB1otjq0kREyihYiHiQAF87o25oySt/aYmfj42fN2dw7ZgFbNqfbXVpIiKAgoWIR7qpQyJTHuxMQo1Adh/J54axC5m8cq/VZYmIKFiIeKrmtcP5dlhXejSMpqDYwWNfr+Wf09ZTWKIpqSJiHQULEQ9WI9iPj4Z04JHLUzAM+HzJHm5+fwn7j5+wujQRqaYULEQ8nN1m8LcrGvLRnR0IC/BhTfpx+r+9gEU7M60uTUSqIQULES/Rq3EM3w3vRtNaYRzJK+K2D5cybt5OnE5NSRWRqqNgIeJF6tQMYspDnflL2wQcThj5wxaGTVxNbmGJ1aWJSDWhYCHiZQJ87bx2Y0v+77rm+NoNvl9/gOveWcjOw7lWlyYi1YCChYgXMgyD2y+ty6T7OhEb5s+OjFwGjFnIzA0HrS5NRLycgoWIF2tXtwbfDu9Kx6RIcgtLeODzlbw8cwulagUuIpVEwULEy8WEBjDhnku4u2sSAGPn7OTOj5ZxNK/I4spExBspWIhUA752G/+6pilvDWpDoK+dBTsy6f/2AtbtPW51aSLiZRQsRKqRa1vFM21oF5Kigtl3/AQDxy7mw/m7tEqqiLiMgoVINdMoLpTpw7rQp2ksRaUOXvp+M3d8tIxD2QVWlyYiXkDBQqQaCgvw5f3b2/H/rm9OgK+NBTsy6fvmPM0aEZGLpmAhUk0ZhsHgS+ry3fBuNIsP43h+MQ98vpK/T15HnhpqicgFUrAQqeYaxIQw9aEu3N8jGcOAScvTuebtBaxNP251aSLigRQsRAQ/HxtP92vChHsuIS4sgNTMPP4ydhHv/LpDPS9EpEIULESkTOf6Ucwc0Y2rW9SixOHk1Z+2MuiDJezTMuwiUk4KFiJyhoggP8bc2oZXB7Yk2M/OstSjXPnmPGas3W91aSLiARQsROQPDMPgxvaJ/PBIN1onRpBTUMLDX6zmsa/WaqVUETkvBQsROae6NYP5+oFOPHxZA2wGTF61l6vfms/qPcesLk1E3JSChYicl6/dxqN9GjHpvk7Ujghk95F8Br63mDH/266BnSLyBwoWIlIuHZMi+eGRblzTshalDievzdqmgZ0i8gcKFiJSbuGBvrw9qA2v3diqbGBnvzfn8d06DewUEZOChYhUiGEYDGyXwPcPd6NVYgTZBSUMm7iaJ75eq46dIqJgISIXpl5UMN880IlhvRpgGPD1SnNgp5ZiF6neFCxE5IL52m083rcRk+69lPjwANKO5DNw7GI+XZyG06mBnSLVkYKFiFy0S5Jr8uMj3enbzFyK/dnpGxn2xWpyCoqtLk1EqpiChYi4RHiQL+/d1o5/XdMUH5vB9+sOcO2YhWzan211aSJShRQsRMRlDMPg7q5JfPVAJ+LDzcXMrn93IV8u36NLIyLVhIKFiLhc2zo1+P7hbvRqFE1hiYOnJq/nsa/Xkl+kWSMi3q5CwWLs2LG0bNmSsLAwwsLC6NSpEz/++GNl1SYiHqxGsB//vbMDT17ZCJsBU1btY8CYhezIyLG6NBGpRBUKFgkJCfz73/9mxYoVrFixgssuu4wBAwawcePGyqpPRDyYzWbwUM8GTLz3UmJC/dmekUv/txcydfVeq0sTkUpiOC/ywmdkZCSvvvoqd999d7men52dTXh4OFlZWYSFhV3MR4uIBzmcU8iIL1ezcMcRAG7pkMhz/ZsR6Ge3uDIRKY/yHr8veIxFaWkpkyZNIi8vj06dOp3zeYWFhWRnZ5+xiUj1Ex3qz6d3XcIjl6dgGDBpeTr9xyzQrBERL1PhYLF+/XpCQkLw9/fngQceYOrUqTRt2vSczx81ahTh4eFlW2Ji4kUVLCKey24z+NsVDfn87kuICfVnR0Yu1727kI8XpmrWiIiXqPClkKKiIvbs2cPx48eZPHkyH374IXPnzj1nuCgsLKSwsLDs++zsbBITE3UpRKSaO5JbyBPfrON/WzIA6N0khlcGtiIy2M/iykTkbMp7KeSix1j07t2b+vXr8/7777u0MBHxfk6nk08WpTHyhy0UlTqICfXnzZtb07lBlNWlicjvVPoYi1OcTucZZyRERMrLMAyGdEli2tAu1I8OJiOnkMH/XcqrP22huNRhdXkicgEqFCz+8Y9/MH/+fNLS0li/fj3PPPMMc+bMYfDgwZVVn4hUA03jw/h2eFcGdUzE6YR3ft3Jje8tJv1ovtWliUgFVShYHDp0iNtvv51GjRpx+eWXs3TpUmbOnMkVV1xRWfWJSDUR5OfDqBta8u7gtoQF+LAm/ThXjZ7P9DX7NLBTxINc9BiLitIYCxH5M3uP5TNi0hpW7D4GQN9msfzfgObEhAVYXJlI9VVlYyxERFwtoUYQk+67lBG9U/CxGfy08RC9/zOXr1ek6+yFiJtTsBARt+RjtzGid0NmDOtK89phZBeU8MQ367hz/HL2HT9hdXkicg4KFiLi1prGhzHtoS48dWVj/HxszNt2mD7/mctnS3bjcOjshYi7UbAQEbfnY7fxYM/6/PhIN9rXrUFeUSn/mraBWz5YQmpmntXlichvKFiIiMeoHx3CV/d34vn+TQnys7Ms9ShXvjmPcfN2UqqzFyJuQcFCRDyKzWY21fppRHe6NoiisMTByB+2cMPYRew8nGt1eSLVnoKFiHikxMggPru7Iy//pQWhAT6sTT/ONW8tYNKyPZo5ImIhBQsR8ViGYXBzhzrM/lsPujSoyYniUv4+ZT0PTVjF8fwiq8sTqZYULETE48WFB/DZXZfwdL/G+NoNftxwkH6j57N45xGrSxOpdhQsRMQr2GwG9/eoz5QHu5AUFcyBrAJu/XCJFjQTqWIKFiLiVVokhPPd8K7c3P70gmYD31vM7iOalipSFRQsRMTrBPv78PLA0wuarT25oNnklXs1sFOkkilYiIjXuqpFLWaO6E7HpEjyikp57Ou1PDxpDVkniq0uTcRrKViIiFeLjwjki3sv5Ym+jbDbDL5du5+rRs9n6S4N7BSpDAoWIuL17DaDob0a8M0DnahbM4h9x09wywdLeGXmFopKNLBTxJUULESk2mhTpwbfP9yNG9sl4HTCu3N28hd17BRxKQULEalWQvx9ePXGVowd3JbwQF/W78vimrcWMGHpbg3sFHEBBQsRqZb6tajFTyO6l3XsfGbqBu79dCVHcgutLk3EoylYiEi1dapj5z+vboKf3cbPmw/R9835/Lo1w+rSRDyWgoWIVGs2m8E93ZKZNrQLDWNDyMwt5K/jl/Pc9A0UFJdaXZ6Ix1GwEBEBmsaHMWNYV4Z0rgfAJ4t3c+Wb8/jflkPWFibiYRQsREROCvC18/y1zfjkro7EhPqTdiSfuz5ewZDxyzRzRKScFCxERH6nR8NofnmsB/f3SMbXbjBn62H6vjGP//f9JrIL1LVT5HwMZxXPr8rOziY8PJysrCzCwsKq8qNFRCosNTOPl77bxC9bzAGdUSF+PNm3MQPbJWCzGRZXJ1J1ynv8VrAQESmHX7dm8H/fbmJXprlKaquEcJ67thlt69SwuDKRqqFgISLiYkUlDj5ZlMboX7aTW1gCwA1tavNUv8bEhgVYXJ1I5Srv8VtjLEREysnPx8a93ZP53+M9uLFdAgBTVu/j8tfn8tWKdHXuFEHBQkSkwmJCA3j1xlZMH9qFVokR5BaW8OQ367j30xVk5BRYXZ6IpRQsREQuUKvECKY82Jm/92t8snNnBn3fmMcP6w9YXZqIZRQsREQugt1m8ECP+swY3oWmtcI4ll/MQxNW8cik1RzPL7K6PJEqp2AhIuICjePCmDa0C8Mva4DNgOlr9tP3zXnM0bojUs0oWIiIuIifj43H+jRi8oOdSY4O5lB2IUPGL+cfU9eTd3IWiYi3U7AQEXGxNnVq8P3wbvy1Sz0AJi7dw5Wj57Es9ai1hYlUAQULEZFKEOhn57n+zZh47yXUjggk/egJbh63mMe+WsuBrBNWlydSaRQsREQqUef6Ucwc0Y2b2yfidMLkVXvp9docXp+1tazJlog3UedNEZEqsnrPMUb+sJnlaccAiArx59ErGnJT+wR87Po7T9ybWnqLiLghp9PJTxsP8e8fN5N2JB+AhrEhPH1VE3o2jMYwtLCZuCcFCxERN1ZU4mDC0t2M/mU7x/PNpdi7NojiH1c1oWm8/m8U96NgISLiAbJOFPPOrzv4eGEaRaUODAMGtk3giSsbEROqhc3EfShYiIh4kPSj+bzy01a+XbsfgIggX14c0Jz+LWvp8oi4Ba1uKiLiQRIjg3h7UBumPtSZZvFhHM8v5uEvVvPQhFUcyS20ujyRclOwEBFxI23q1GDa0C6M6J2Cj83gxw0H6fPGPH7UwmbiIRQsRETcjK/dxojeDZk2tAuN40I5klfEgxNW8fAXqzmWp4XNxL0pWIiIuKnmtcOZPqwLw3o1wG4zmLF2P33enMfPmw5ZXZrIOSlYiIi4MX8fO4/3bcSUBzvTICaEwzmF3PPpCh77ai1ZJ4qtLk/kDxQsREQ8QKvECL4b3pX7uydjGGZr8L5vzGPmhoNU8eQ+kfPSdFMREQ+zcvdRHv96HamZeQC0qB3OiN4pXNY4RlNTpdKoj4WIiBc7UVTKmF+3M35hGvlFpQC0SghnRO+G9Gyk1uDiegoWIiLVwJHcQsbN38Wni3ZzovhkwEiMYETvFK09Ii6lYCEiUo1k5hYybt4uPl2cRkGxA4A2dSIY0bsh3VOiFDDkoilYiIhUQ4dzCnl/7k4+W7KbwhIzYLSrW4PHrmhI5wZRFlcnnkzBQkSkGsvIKeC9ObuYsPR0wOjfKp5/XdNEi5vJBamUtUJGjRpFhw4dCA0NJSYmhuuuu46tW7dedLEiIuJaMaEBPNu/KfOf7MUdnepiM+Dbtfu5/PW5TFi6G4dDU1SlclQoWMydO5ehQ4eyZMkSZs+eTUlJCX369CEvL6+y6hMRkYsQExbAiwOaM31oV5rXDiOnoIRnpm7gxvcXs/VgjtXliRe6qEshhw8fJiYmhrlz59K9e/dyvUaXQkRErFFS6uDTxbt5fdZW8opK8bEZ3Ns9mYcvSyHQz251eeLmqmTZ9KysLAAiIyMv5m1ERKQK+Nht3NU1idmP9qBP01hKHE7GztlJ3zfnMXfbYavLEy9xwWcsnE4nAwYM4NixY8yfP/+czyssLKSwsLDs++zsbBITE3XGQkTEYj9tPMjzMzZyIKsAgGtbxfNPDe6Uc6j0MxbDhg1j3bp1fPHFF+d93qhRowgPDy/bEhMTL/QjRUTEhfo2i2P2oz34a5d62AyYcXJw5/tzd1JwstmWSEVd0BmL4cOHM23aNObNm0dSUtJ5n6szFiIi7m/d3uP8Y+p6NuzLBqBWeAB/692QG9rWxseu9SqlkvpYOJ1Ohg8fztSpU5kzZw4pKSmVVpiIiFStUoeTKav28sbsbew/eXmkQUwIT/RtRJ+msereWc1VSrB46KGHmDhxItOnT6dRo0Zl94eHhxMYGOjSwkRExBoFxaV8tng378zZwfH8YgDa1ong7/2a0DFJg/Wrq0oJFudKq+PHj2fIkCEuLUxERKyVdaKYcfN28t8FqWXrj1zWOIYnr2xE4zj9/13dqKW3iIi4xKHsAkb/sp0vl6dT6nBiGHB9m9r8rXdDEiODrC5PqoiChYiIuNTOw7m8PmsrP6w/CICv3eCm9okMu6wBtcLLdzlcPJeChYiIVIq16cd59aetLNiRCYCfj41bO9bhoV711QPDiylYiIhIpVq66wivz9rGsrSjAAT42rijUz3u755MzRB/i6sTV1OwEBGRSud0OlmwI5PXZ21jTfpxAIL97AzpUo/7utUnPMjX2gLFZRQsRESkyjidTn7dmsHrs7axcb/ZZCs0wId7uiZzV9d6hAYoYHg6BQsREalyTqeTnzYe4o3Z29h6yFyWvUaQL8MvS2HwpXXw99Eqqp5KwUJERCzjcDj5fv0B3pi9jV2ZeQAk1Ajk8T6NuLZVPDabunh6GgULERGxXEmpg69Xmm3CM3LMdaOa1Arj7/0a0z0lSm3CPYiChYiIuI0TRaV8tDCV9+bsJKewBIDO9Wvy936NaZkQYW1xUi4KFiIi4naO5hXxzq87+GzxbopKzTbhV7esxRN9GlEvKtji6uR8FCxERMRtpR/N543Z25i6Zh9OJ/jYDG7ukMj93etTp6bahLsjBQsREXF7m/Zn88pPW5iz9TAANgOualGL+7vXp0VCuMXVyW8pWIiIiMdYsusIY+fsZO62w2X3da5fk/t71NcgTzehYCEiIh5n0/5sPpi/i2/X7qfEYR6eGseFcn+PZK5pGY+v3WZxhdWXgoWIiHisfcdP8NGCVL5Ytof8olIA4sMDuLtbMrd0SCTY38fiCqsfBQsREfF4WfnFfL50N+MXppGZa/bBCAvwYfCldRnSuR6xYVpNtaooWIiIiNcoKC5l6up9fDBvV1knT1+7Qf9W8dzbLZkmtXQ8qWwKFiIi4nUcDic/bz7Eh/NTy5ZrB+jaIIp7uiXRo2G0BnpWEgULERHxamvTj/PB/F38uOEgpScHejaKDeXubkkMaB2vBc9cTMFCRESqhfSj+YxfmMaXy/eQd3KgZ3SoP3d2qsvtl9YjPEhLtruCgoWIiFQrWSeKmbRsD+MXpnEwuwCAEH8f7uxcl7u7JhMZ7GdxhZ5NwUJERKqlohIH36/fz/tzd7HlYA4AQX52bru0Lvd2SyY61N/iCj2TgoWIiFRrDoeT2ZsP8fb/trNhXzYAAb42BnWswwM96muqagUpWIiIiABOp5Nft2bw1i87WJN+HAA/Hxs3t0/kgZ71qR0RaG2BHkLBQkRE5DecTicLdmTy1i/bWZ52DDB7YQxsl8ADPepTt6aWbT8fBQsREZGzcDqdLNl1lLd+2c7iXUcAMAy4rFEMd3auRzctenZWChYiIiJ/YkXaUcb8uqNs2XaA5OhghnSuxw1tEwjRmiRlFCxERETKadfhXD5dvJtvVu4lt7AEgFB/Hwa2T+COTvVIitJlEgULERGRCsotLGHyyr18sjiNXYfzyu7v2SiaIZ3r0T0lGputel4mUbAQERG5QA6Hk/k7MvlkURq/bs3g1JGyXs0gBnWsw8B2CdQMqV79MBQsREREXCAtM49PF+/m6xXp5Jy8TOJrN+jbLI5bL6lDp+Sa1WKwp4KFiIiIC+UVlvDt2v18sWwPa/dmld2fFBXMLR0Svf4shoKFiIhIJdmwL4svlu1h+pr9ZYM9vf0shoKFiIhIJTt1FmPisj2s+91ZjLu6JnFjuwQCfL1j+XYFCxERkSq0YV8WE5ftYfrqfWXLt0cG+3FHp7rc0amex6+uqmAhIiJigbzCEr5ekc6HC1LZe+wEYC5+dmO7RO7pluSxrcMVLERERCxUUurghw0HGTdvZ9nqqjYD+jWvxX3dk2mVGGFtgRWkYCEiIuIGnE4ni3ce4f15u5i77XTr8EuSIrm/RzI9G8Z4RNMtBQsRERE3s+VgNuPm7WLGmv2UOMzDb/3oYP7aJYkb2tYmyM991yZRsBAREXFTB7JOMH5hGhOX7imbrhoe6MugjnW4s3NdaoUHWlzhHylYiIiIuLmcgmK+XrGXjxelsedoPgB2m8FVLWpxV5d6tKlTw+IKT1OwEBER8RClDie/bD7ERwtTWbLraNn9bepEcFeXJK5sHoev3WZhhQoWIiIiHmnj/izGL0xjxpr9FJU6AKgVHsDAdgn0bhJLi9rhlgz2VLAQERHxYIdzCpmwdDefL9lNZm5R2f0xof5c3iSW3k1i6NIgqso6eypYiIiIeIHCklJ+XH+QWZsOMnfr4bKunmA23uqWEk3vJjFc1jiW6NDKWwRNwUJERMTLFJaUsmTXUX7ZfIifNx1if1ZB2WOGAa0TI+jdJJab2ie6PGQoWIiIiHgxp9PJpgPZ/LI5g583HzpjEbS5T/R0eevw8h6/3bcTh4iIiJyTYRg0iw+nWXw4D1+ewqHsAn7ZnMHG/VmWrkeiYCEiIuIFYsMCuPWSOlaXgbWTYkVERMSrKFiIiIiIyyhYiIiIiMtUOFjMmzeP/v37Ex8fj2EYTJs2rRLKEhEREU9U4WCRl5dHq1atGDNmTGXUIyIiIh6swrNC+vXrR79+/SqjFhEREfFwGmMhIiIiLlPpfSwKCwspLCws+z47O7uyP1JEREQsUulnLEaNGkV4eHjZlpiYWNkfKSIiIhap9GDx9NNPk5WVVbalp6dX9keKiIiIRSr9Uoi/vz/+/pW3jKuIiIi4jwoHi9zcXHbs2FH2fWpqKmvWrCEyMpI6dazvUS4iIiLWqXCwWLFiBb169Sr7/tFHHwXgzjvv5OOPP3ZZYSIiIuJ5KhwsevbsidPpvOAPPPVazQ4RERHxHKeO23+WAap82fScnBwAzQ4RERHxQDk5OYSHh5/zccN5MacfLoDD4WD//v2EhoZiGIbL3jc7O5vExETS09MJCwtz2fvKxdO+cU/aL+5L+8Y9Vff94nQ6ycnJIT4+Hpvt3JNKq/yMhc1mIyEhodLePywsrFrucE+gfeOetF/cl/aNe6rO++V8ZypOUUtvERERcRkFCxEREXEZrwkW/v7+PPfcc2rG5Ya0b9yT9ov70r5xT9ov5VPlgzdFRETEe3nNGQsRERGxnoKFiIiIuIyChYiIiLiMgoWIiIi4jNcEi3fffZekpCQCAgJo164d8+fPt7qkamXevHn079+f+Ph4DMNg2rRpZzzudDp5/vnniY+PJzAwkJ49e7Jx40Zriq1GRo0aRYcOHQgNDSUmJobrrruOrVu3nvEc7RtrjB07lpYtW5Y1W+rUqRM//vhj2ePaL+5h1KhRGIbBiBEjyu7Tvjk/rwgWX375JSNGjOCZZ55h9erVdOvWjX79+rFnzx6rS6s28vLyaNWqFWPGjDnr46+88gr/+c9/GDNmDMuXLycuLo4rrriibO0YqRxz585l6NChLFmyhNmzZ1NSUkKfPn3Iy8sre472jTUSEhL497//zYoVK1ixYgWXXXYZAwYMKDtAab9Yb/ny5YwbN46WLVuecb/2zZ9weoGOHTs6H3jggTPua9y4sfPvf/+7RRVVb4Bz6tSpZd87HA5nXFyc89///nfZfQUFBc7w8HDne++9Z0GF1VdGRoYTcM6dO9fpdGrfuJsaNWo4P/zwQ+0XN5CTk+NMSUlxzp4929mjRw/nI4884nQ69W+mPDz+jEVRURErV66kT58+Z9zfp08fFi1aZFFV8lupqakcPHjwjH3k7+9Pjx49tI+qWFZWFgCRkZGA9o27KC0tZdKkSeTl5dGpUyftFzcwdOhQrr76anr37n3G/do3f67KFyFztczMTEpLS4mNjT3j/tjYWA4ePGhRVfJbp/bD2fbR7t27rSipWnI6nTz66KN07dqV5s2bA9o3Vlu/fj2dOnWioKCAkJAQpk6dStOmTcsOUNov1pg0aRIrV65kxYoVf3hM/2b+nMcHi1N+vwS70+l06bLscvG0j6w1bNgw1q1bx4IFC/7wmPaNNRo1asSaNWs4fvw4kydP5s4772Tu3Lllj2u/VL309HQeeeQRZs2aRUBAwDmfp31zbh5/KSQqKgq73f6HsxMZGRl/SJRijbi4OADtIwsNHz6cGTNm8Ouvv5KQkFB2v/aNtfz8/GjQoAHt27dn1KhRtGrVitGjR2u/WGjlypVkZGTQrl07fHx88PHxYe7cubz11lv4+PiU/f61b87N44OFn58f7dq1Y/bs2WfcP3v2bDp37mxRVfJbSUlJxMXFnbGPioqKmDt3rvZRJXM6nQwbNowpU6bwv//9j6SkpDMe175xL06nk8LCQu0XC11++eWsX7+eNWvWlG3t27dn8ODBrFmzhuTkZO2bP+EVl0IeffRRbr/9dtq3b0+nTp0YN24ce/bs4YEHHrC6tGojNzeXHTt2lH2fmprKmjVriIyMpE6dOowYMYKRI0eSkpJCSkoKI0eOJCgoiFtvvdXCqr3f0KFDmThxItOnTyc0NLTsr6zw8HACAwPL5udr31S9f/zjH/Tr14/ExERycnKYNGkSc+bMYebMmdovFgoNDS0bg3RKcHAwNWvWLLtf++ZPWDchxbXeeecdZ926dZ1+fn7Otm3blk2nk6rx66+/OoE/bHfeeafT6TSnaD333HPOuLg4p7+/v7N79+7O9evXW1t0NXC2fQI4x48fX/Yc7Rtr3HXXXWX/Z0VHRzsvv/xy56xZs8oe135xH7+dbup0at/8GS2bLiIiIi7j8WMsRERExH0oWIiIiIjLKFiIiIiIyyhYiIiIiMsoWIiIiIjLKFiIiIiIyyhYiIiIiMsoWIiIiIjLKFiIiIiIyyhYiIiIiMsoWIiIiIjLKFiIiIiIy/x/hFhzg6aHO2gAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot \n",
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "pyplot.legend() \n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index = y_tokenizer.index_word\n",
    "reverse_news_words_index = X_tokenizer.index_word\n",
    "target_word_index = y_tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs = enc_inputs, outputs = [enc_outputs, h3, c3])\n",
    "\n",
    "decoder_h = Input(shape=(latent_dim,))\n",
    "decoder_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_len_news, latent_dim))\n",
    "\n",
    "\n",
    "dec_emb2 = dec_embedding(decoder_inputs)\n",
    "\n",
    "dec_output2, dec_h2, dec_c2 = dec_lstm(dec_emb2, initial_state=[decoder_h, decoder_c])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "attn_out_inf, attn_state_inf = attn_layer([decoder_hidden_state_input, dec_output2])\n",
    "\n",
    "dec_inf_concat = Concatenate(axis=-1, name='concat')([dec_output2, attn_out_inf])\n",
    "\n",
    "\n",
    "dec_output2 = decoder_dense(dec_inf_concat)\n",
    "\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input, decoder_h, decoder_c], [dec_output2] + [dec_h2, dec_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 100)    776200      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 300),  481200      ['embedding_1[1][0]',            \n",
      "                                 (None, 300),                     'input_3[0][0]',                \n",
      "                                 (None, 300)]                     'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 47, 300)]    0           []                               \n",
      "                                                                                                  \n",
      " attention_layer (AttentionLaye  ((None, None, 300),  180300     ['input_5[0][0]',                \n",
      " r)                              (None, None, 47))                'lstm_3[1][0]']                 \n",
      "                                                                                                  \n",
      " concat (Concatenate)           (None, None, 600)    0           ['lstm_3[1][0]',                 \n",
      "                                                                  'attention_layer[1][0]']        \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 7762)  4664962     ['concat[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,102,662\n",
      "Trainable params: 6,102,662\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_sequence):\n",
    "    e_out, e_h, e_c = encoder_model(input_sequence)\n",
    "\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    target_seq[0,0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "\n",
    "\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        \n",
    "        sample_token_index = np.argmax(output_tokens[0,-1,:])\n",
    "        sampled_token = reverse_target_word_index[sample_token_index]\n",
    "\n",
    "        if sampled_token!='eostok':\n",
    "            decoded_sentence+= ' ' + sampled_token\n",
    "\n",
    "        if (sampled_token=='eostok' or len(decoded_sentence.split())>=(max_len_headline-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1,1))\n",
    "\n",
    "        target_seq[0,0] = target_word_index[sampled_token]\n",
    "\n",
    "\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "        newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if(i!=0):\n",
    "        newString=newString+reverse_news_words_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: six months stabbed left playing hand czech tennis player petra kvitova first tournament classic sunday world number 12 kvitova playing second tournament since december incident beat australian 46 63 63 birmingham kvitova returned action french open late may \n",
      "Original summary: czech tennis player wins title months after being stabbed \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Predicted summary:  what is hold icj from icj in icj in jadhav\n",
      "\n",
      "\n",
      "Review: farmers 78 villages maharashtra reportedly planning go indefinite fast protest alleged acquisition farm land industrial corridor despite project getting scaled original size 78 villages activists said officials maintained planning land acquisition \n",
      "Original summary: maha farmers to fast to protest land acquisition \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Predicted summary:  delhi man to get in protest in delhi bjp\n",
      "\n",
      "\n",
      "Review: launching desh ka aam scheme thursday pm narendra modi said dream see person wears slippers fly lives middle class aviation considered domain select changed added \n",
      "Original summary: wanted to see people wearing on \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted summary:  modi should pm modi to relook in modi katrinas modi\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 4):\n",
    "  print(\"Review:\",seq2text(X_test[i]))\n",
    "  print(\"Original summary:\",seq2summary(y_test[i]))\n",
    "  print(\"Predicted summary:\",decode_sequence(X_test[i].reshape(1,max_len_news)))\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'start',\n",
       " 2: 'end',\n",
       " 3: 'to',\n",
       " 4: 'in',\n",
       " 5: 'for',\n",
       " 6: 'of',\n",
       " 7: 'on',\n",
       " 8: 'delhi',\n",
       " 9: 'at',\n",
       " 10: 'from',\n",
       " 11: 'with',\n",
       " 12: 'after',\n",
       " 13: 'india',\n",
       " 14: 'by',\n",
       " 15: 'over',\n",
       " 16: 'be',\n",
       " 17: 'govt',\n",
       " 18: 'as',\n",
       " 19: 'not',\n",
       " 20: 'up',\n",
       " 21: 'is',\n",
       " 22: 'man',\n",
       " 23: 'the',\n",
       " 24: 'mumbai',\n",
       " 25: 'bjp',\n",
       " 26: 'against',\n",
       " 27: 'will',\n",
       " 28: 'indian',\n",
       " 29: 'report',\n",
       " 30: 'modi',\n",
       " 31: 'pm',\n",
       " 32: 'us',\n",
       " 33: 'was',\n",
       " 34: 'cr',\n",
       " 35: 'police',\n",
       " 36: 'his',\n",
       " 37: 'crore',\n",
       " 38: 'woman',\n",
       " 39: 'film',\n",
       " 40: 'cm',\n",
       " 41: 'new',\n",
       " 42: 'case',\n",
       " 43: 'arrested',\n",
       " 44: 'no',\n",
       " 45: 'lakh',\n",
       " 46: 'who',\n",
       " 47: 'it',\n",
       " 48: 'first',\n",
       " 49: 'sc',\n",
       " 50: 'ban',\n",
       " 51: 'indias',\n",
       " 52: 'says',\n",
       " 53: 'people',\n",
       " 54: 'aap',\n",
       " 55: 'pak',\n",
       " 56: 'and',\n",
       " 57: 'my',\n",
       " 58: 'get',\n",
       " 59: 'reports',\n",
       " 60: 'st',\n",
       " 61: 'out',\n",
       " 62: 'women',\n",
       " 63: 'has',\n",
       " 64: 'trump',\n",
       " 65: 'if',\n",
       " 66: 'attack',\n",
       " 67: 'years',\n",
       " 68: 'air',\n",
       " 69: 'can',\n",
       " 70: 'kejriwal',\n",
       " 71: 'have',\n",
       " 72: 'me',\n",
       " 73: 'china',\n",
       " 74: 'hc',\n",
       " 75: 'gets',\n",
       " 76: 'jk',\n",
       " 77: 'her',\n",
       " 78: 'may',\n",
       " 79: 'chief',\n",
       " 80: 'asks',\n",
       " 81: 'team',\n",
       " 82: 'army',\n",
       " 83: 'airport',\n",
       " 84: 'time',\n",
       " 85: 'its',\n",
       " 86: 'off',\n",
       " 87: 'yrs',\n",
       " 88: 'post',\n",
       " 89: 'yrold',\n",
       " 90: 'actor',\n",
       " 91: 'take',\n",
       " 92: 'gst',\n",
       " 93: 'like',\n",
       " 94: 'day',\n",
       " 95: 'being',\n",
       " 96: 'pakistan',\n",
       " 97: 'found',\n",
       " 98: 'killed',\n",
       " 99: 'mp',\n",
       " 100: 'one',\n",
       " 101: 'congress',\n",
       " 102: 'world',\n",
       " 103: 'son',\n",
       " 104: 'maharashtra',\n",
       " 105: 'leader',\n",
       " 106: 'polls',\n",
       " 107: 'kohli',\n",
       " 108: 'an',\n",
       " 109: 'held',\n",
       " 110: 'actress',\n",
       " 111: 'jail',\n",
       " 112: 'year',\n",
       " 113: 'claims',\n",
       " 114: 'minister',\n",
       " 115: 'are',\n",
       " 116: 'salman',\n",
       " 117: 'pic',\n",
       " 118: 'worth',\n",
       " 119: 'wins',\n",
       " 120: 'maha',\n",
       " 121: 'during',\n",
       " 122: 'metro',\n",
       " 123: 'car',\n",
       " 124: 'kumar',\n",
       " 125: 'online',\n",
       " 126: 'bihar',\n",
       " 127: 'gujarat',\n",
       " 128: 'dont',\n",
       " 129: 'th',\n",
       " 130: 'body',\n",
       " 131: 'protest',\n",
       " 132: 'srk',\n",
       " 133: 'farmers',\n",
       " 134: 'about',\n",
       " 135: 'dies',\n",
       " 136: 'him',\n",
       " 137: 'death',\n",
       " 138: 'students',\n",
       " 139: 'only',\n",
       " 140: 'dead',\n",
       " 141: 'house',\n",
       " 142: 'he',\n",
       " 143: 'cong',\n",
       " 144: 'court',\n",
       " 145: 'staff',\n",
       " 146: 'uk',\n",
       " 147: 'make',\n",
       " 148: 'bank',\n",
       " 149: 'prez',\n",
       " 150: 'made',\n",
       " 151: 'school',\n",
       " 152: 'win',\n",
       " 153: 'girl',\n",
       " 154: 'punjab',\n",
       " 155: 'test',\n",
       " 156: 'two',\n",
       " 157: 'noida',\n",
       " 158: 'into',\n",
       " 159: 'gandhi',\n",
       " 160: 'note',\n",
       " 161: 'rape',\n",
       " 162: 'yearold',\n",
       " 163: 'slams',\n",
       " 164: 'singh',\n",
       " 165: 'khan',\n",
       " 166: 'men',\n",
       " 167: 'open',\n",
       " 168: 'national',\n",
       " 169: 'what',\n",
       " 170: 'home',\n",
       " 171: 'show',\n",
       " 172: 'notes',\n",
       " 173: 'pay',\n",
       " 174: 'than',\n",
       " 175: 'when',\n",
       " 176: 'gurugram',\n",
       " 177: 'fire',\n",
       " 178: 'akshay',\n",
       " 179: 'kids',\n",
       " 180: 'government',\n",
       " 181: 'worlds',\n",
       " 182: 'priyanka',\n",
       " 183: 'away',\n",
       " 184: 'chinese',\n",
       " 185: 'fake',\n",
       " 186: 'seeks',\n",
       " 187: 'probe',\n",
       " 188: 'before',\n",
       " 189: 'days',\n",
       " 190: 'wont',\n",
       " 191: 'baahubali',\n",
       " 192: 'give',\n",
       " 193: 'go',\n",
       " 194: 'should',\n",
       " 195: 'wife',\n",
       " 196: 'play',\n",
       " 197: 'centre',\n",
       " 198: 'ec',\n",
       " 199: 'delhis',\n",
       " 200: 'use',\n",
       " 201: 'we',\n",
       " 202: 'sets',\n",
       " 203: 'cant',\n",
       " 204: 'kashmir',\n",
       " 205: 'suicide',\n",
       " 206: 'video',\n",
       " 207: 'set',\n",
       " 208: 'mlas',\n",
       " 209: 'under',\n",
       " 210: 'denies',\n",
       " 211: 'mla',\n",
       " 212: 'president',\n",
       " 213: 'shah',\n",
       " 214: 'cricket',\n",
       " 215: 'stop',\n",
       " 216: 'last',\n",
       " 217: 'months',\n",
       " 218: 'temple',\n",
       " 219: 'train',\n",
       " 220: 'money',\n",
       " 221: 'flight',\n",
       " 222: 'head',\n",
       " 223: 'boy',\n",
       " 224: 'films',\n",
       " 225: 'shares',\n",
       " 226: 'war',\n",
       " 227: 'director',\n",
       " 228: 'all',\n",
       " 229: 'come',\n",
       " 230: 'back',\n",
       " 231: 'rahul',\n",
       " 232: 'accused',\n",
       " 233: 'old',\n",
       " 234: 'you',\n",
       " 235: 'record',\n",
       " 236: 'big',\n",
       " 237: 'life',\n",
       " 238: 'their',\n",
       " 239: 'media',\n",
       " 240: 'daughter',\n",
       " 241: 'more',\n",
       " 242: 'calls',\n",
       " 243: 'bans',\n",
       " 244: 'kills',\n",
       " 245: 'shows',\n",
       " 246: 'south',\n",
       " 247: 'goa',\n",
       " 248: 'gold',\n",
       " 249: 'top',\n",
       " 250: 'that',\n",
       " 251: 'or',\n",
       " 252: 'tn',\n",
       " 253: 'how',\n",
       " 254: 'now',\n",
       " 255: 'kapil',\n",
       " 256: 'sena',\n",
       " 257: 'work',\n",
       " 258: 'had',\n",
       " 259: 'railways',\n",
       " 260: 'launch',\n",
       " 261: 'whatsapp',\n",
       " 262: 'fight',\n",
       " 263: 'pradesh',\n",
       " 264: 'due',\n",
       " 265: 'free',\n",
       " 266: 'jawans',\n",
       " 267: 'must',\n",
       " 268: 'rss',\n",
       " 269: 'tv',\n",
       " 270: 'power',\n",
       " 271: 'study',\n",
       " 272: 'most',\n",
       " 273: 'family',\n",
       " 274: 'award',\n",
       " 275: 'sasikala',\n",
       " 276: 'seats',\n",
       " 277: 'strike',\n",
       " 278: 'orders',\n",
       " 279: 'security',\n",
       " 280: 'plans',\n",
       " 281: 'party',\n",
       " 282: 'ceo',\n",
       " 283: 'twitter',\n",
       " 284: 'bcci',\n",
       " 285: 'female',\n",
       " 286: 'child',\n",
       " 287: 'hits',\n",
       " 288: 'using',\n",
       " 289: 'why',\n",
       " 290: 'every',\n",
       " 291: 'schools',\n",
       " 292: 'amid',\n",
       " 293: 'outside',\n",
       " 294: 'got',\n",
       " 295: 'panel',\n",
       " 296: 'state',\n",
       " 297: 'offers',\n",
       " 298: 'cash',\n",
       " 299: 'call',\n",
       " 300: 'were',\n",
       " 301: 'next',\n",
       " 302: 'water',\n",
       " 303: 'release',\n",
       " 304: 'station',\n",
       " 305: 'office',\n",
       " 306: 'theatres',\n",
       " 307: 'officer',\n",
       " 308: 'ganguly',\n",
       " 309: 'they',\n",
       " 310: 'kerala',\n",
       " 311: 'mamata',\n",
       " 312: 'board',\n",
       " 313: 'plane',\n",
       " 314: 'while',\n",
       " 315: 'former',\n",
       " 316: 'salary',\n",
       " 317: 'akhilesh',\n",
       " 318: 'support',\n",
       " 319: 'makes',\n",
       " 320: 'want',\n",
       " 321: 'cop',\n",
       " 322: 'star',\n",
       " 323: 'passes',\n",
       " 324: 'ram',\n",
       " 325: 'im',\n",
       " 326: 'dhoni',\n",
       " 327: 'firm',\n",
       " 328: 'biggest',\n",
       " 329: 'sp',\n",
       " 330: 'donald',\n",
       " 331: 'meet',\n",
       " 332: 'bengaluru',\n",
       " 333: 'aadhaar',\n",
       " 334: 'our',\n",
       " 335: 'workers',\n",
       " 336: 'birthday',\n",
       " 337: 'haryana',\n",
       " 338: 'become',\n",
       " 339: 'rules',\n",
       " 340: 'kolkata',\n",
       " 341: 'bmc',\n",
       " 342: 'but',\n",
       " 343: 'isis',\n",
       " 344: 'do',\n",
       " 345: 'husband',\n",
       " 346: 'food',\n",
       " 347: 'let',\n",
       " 348: 'this',\n",
       " 349: 'parliament',\n",
       " 350: 'nitish',\n",
       " 351: 'becomes',\n",
       " 352: 'own',\n",
       " 353: 'public',\n",
       " 354: 'leaders',\n",
       " 355: 'russia',\n",
       " 356: 'wants',\n",
       " 357: 'sex',\n",
       " 358: 'working',\n",
       " 359: 'cops',\n",
       " 360: 'shot',\n",
       " 361: 'never',\n",
       " 362: 'stations',\n",
       " 363: 'down',\n",
       " 364: 'bill',\n",
       " 365: 'aamir',\n",
       " 366: 'assembly',\n",
       " 367: 'seized',\n",
       " 368: 'injured',\n",
       " 369: 'mother',\n",
       " 370: 'three',\n",
       " 371: 'dept',\n",
       " 372: 'special',\n",
       " 373: 'refuses',\n",
       " 374: 'list',\n",
       " 375: 'near',\n",
       " 376: 'land',\n",
       " 377: 'them',\n",
       " 378: 'meeting',\n",
       " 379: 'did',\n",
       " 380: 'die',\n",
       " 381: 'tax',\n",
       " 382: 'black',\n",
       " 383: 'ministers',\n",
       " 384: 'demonetisation',\n",
       " 385: 'cases',\n",
       " 386: 'named',\n",
       " 387: 'help',\n",
       " 388: 'kovind',\n",
       " 389: 'hours',\n",
       " 390: 'announces',\n",
       " 391: 'part',\n",
       " 392: 'road',\n",
       " 393: 'wimbledon',\n",
       " 394: 'muslims',\n",
       " 395: 'look',\n",
       " 396: 'illegal',\n",
       " 397: 'issue',\n",
       " 398: 'paid',\n",
       " 399: 'tells',\n",
       " 400: 'rbi',\n",
       " 401: 'name',\n",
       " 402: 'poll',\n",
       " 403: 'hospital',\n",
       " 404: 'jio',\n",
       " 405: 'indians',\n",
       " 406: 'pregnant',\n",
       " 407: 'cbi',\n",
       " 408: 'coach',\n",
       " 409: 'bus',\n",
       " 410: 'victims',\n",
       " 411: 'takes',\n",
       " 412: 'plea',\n",
       " 413: 'didnt',\n",
       " 414: 'she',\n",
       " 415: 'gives',\n",
       " 416: 'baby',\n",
       " 417: 'jaitley',\n",
       " 418: 'face',\n",
       " 419: 'pics',\n",
       " 420: 'doesnt',\n",
       " 421: 'uttar',\n",
       " 422: 'caught',\n",
       " 423: 'virat',\n",
       " 424: 'mob',\n",
       " 425: 'corruption',\n",
       " 426: 'died',\n",
       " 427: 'shahid',\n",
       " 428: 'election',\n",
       " 429: 'falls',\n",
       " 430: 'notice',\n",
       " 431: 'muslim',\n",
       " 432: 'rajinikanth',\n",
       " 433: 'tamil',\n",
       " 434: 'group',\n",
       " 435: 'park',\n",
       " 436: 'couple',\n",
       " 437: 'suspended',\n",
       " 438: 'bsf',\n",
       " 439: 'together',\n",
       " 440: 'civic',\n",
       " 441: 'resignation',\n",
       " 442: 'poor',\n",
       " 443: 'tweet',\n",
       " 444: 'du',\n",
       " 445: 'launches',\n",
       " 446: 'liquor',\n",
       " 447: 'action',\n",
       " 448: 'father',\n",
       " 449: 'min',\n",
       " 450: 'phone',\n",
       " 451: 'candidate',\n",
       " 452: 'russian',\n",
       " 453: 'say',\n",
       " 454: 'role',\n",
       " 455: 'banks',\n",
       " 456: 'iaf',\n",
       " 457: 'hindu',\n",
       " 458: 'mcd',\n",
       " 459: 'union',\n",
       " 460: 'google',\n",
       " 461: 'mallya',\n",
       " 462: 'icc',\n",
       " 463: 'row',\n",
       " 464: 'job',\n",
       " 465: 'trumps',\n",
       " 466: 'right',\n",
       " 467: 'without',\n",
       " 468: 'border',\n",
       " 469: 'assam',\n",
       " 470: 'booked',\n",
       " 471: 'london',\n",
       " 472: 'would',\n",
       " 473: 'hit',\n",
       " 474: 'yogi',\n",
       " 475: 'filed',\n",
       " 476: 'loss',\n",
       " 477: 'plan',\n",
       " 478: 'saudi',\n",
       " 479: 'driver',\n",
       " 480: 'allow',\n",
       " 481: 'colleges',\n",
       " 482: 'since',\n",
       " 483: 'sri',\n",
       " 484: 'university',\n",
       " 485: 'chennai',\n",
       " 486: 'ministry',\n",
       " 487: 'captain',\n",
       " 488: 'your',\n",
       " 489: 'complaint',\n",
       " 490: 'loan',\n",
       " 491: 'scam',\n",
       " 492: 'could',\n",
       " 493: 'jallikattu',\n",
       " 494: 'warns',\n",
       " 495: 'cut',\n",
       " 496: 'claim',\n",
       " 497: 'officials',\n",
       " 498: 'data',\n",
       " 499: 'doctors',\n",
       " 500: 'best',\n",
       " 501: 'picture',\n",
       " 502: 'cms',\n",
       " 503: 'system',\n",
       " 504: 'fined',\n",
       " 505: 'loses',\n",
       " 506: 'red',\n",
       " 507: 'wanted',\n",
       " 508: 'files',\n",
       " 509: 'issues',\n",
       " 510: 'week',\n",
       " 511: 'players',\n",
       " 512: 'rajasthan',\n",
       " 513: 'campaign',\n",
       " 514: 'amarnath',\n",
       " 515: 'votes',\n",
       " 516: 'katrina',\n",
       " 517: 'bail',\n",
       " 518: 'tiger',\n",
       " 519: 'install',\n",
       " 520: 'accounts',\n",
       " 521: 'love',\n",
       " 522: 'pilot',\n",
       " 523: 'bombay',\n",
       " 524: 'those',\n",
       " 525: 'terror',\n",
       " 526: 'match',\n",
       " 527: 'trying',\n",
       " 528: 'even',\n",
       " 529: 'seeking',\n",
       " 530: 'cow',\n",
       " 531: 'remark',\n",
       " 532: 'threat',\n",
       " 533: 'accuses',\n",
       " 534: 'aiadmk',\n",
       " 535: 'fans',\n",
       " 536: 'murder',\n",
       " 537: 'hold',\n",
       " 538: 'act',\n",
       " 539: 'violence',\n",
       " 540: 'enter',\n",
       " 541: 'city',\n",
       " 542: 'defence',\n",
       " 543: 'place',\n",
       " 544: 'airtel',\n",
       " 545: 'sunil',\n",
       " 546: 'pranab',\n",
       " 547: 'change',\n",
       " 548: 'bomb',\n",
       " 549: 'any',\n",
       " 550: 'west',\n",
       " 551: 'times',\n",
       " 552: 'birth',\n",
       " 553: 'till',\n",
       " 554: 'soldiers',\n",
       " 555: 'aiims',\n",
       " 556: 'sale',\n",
       " 557: 'term',\n",
       " 558: 'player',\n",
       " 559: 'haasan',\n",
       " 560: 'slammed',\n",
       " 561: 'adityanath',\n",
       " 562: 'used',\n",
       " 563: 'leave',\n",
       " 564: 'high',\n",
       " 565: 'womens',\n",
       " 566: 'swaraj',\n",
       " 567: 'firing',\n",
       " 568: 'upcoming',\n",
       " 569: 'need',\n",
       " 570: 'leaked',\n",
       " 571: 'returns',\n",
       " 572: 'run',\n",
       " 573: 'called',\n",
       " 574: 'too',\n",
       " 575: 'manipur',\n",
       " 576: 'officers',\n",
       " 577: 'accident',\n",
       " 578: 'jolly',\n",
       " 579: 'llb',\n",
       " 580: 'dutt',\n",
       " 581: 'still',\n",
       " 582: 'debut',\n",
       " 583: 'vote',\n",
       " 584: 'doctor',\n",
       " 585: 'oldest',\n",
       " 586: 'cuts',\n",
       " 587: 'militants',\n",
       " 588: 'share',\n",
       " 589: 'budget',\n",
       " 590: 'aus',\n",
       " 591: 'states',\n",
       " 592: 'sachin',\n",
       " 593: 'shiv',\n",
       " 594: 'crash',\n",
       " 595: 'raj',\n",
       " 596: 'girls',\n",
       " 597: 'uses',\n",
       " 598: 'bluru',\n",
       " 599: 'appointed',\n",
       " 600: 'number',\n",
       " 601: 'chairman',\n",
       " 602: 'mukherjee',\n",
       " 603: 'directs',\n",
       " 604: 'lynching',\n",
       " 605: 'wrong',\n",
       " 606: 'indianorigin',\n",
       " 607: 'mulayam',\n",
       " 608: 'tweets',\n",
       " 609: 'modis',\n",
       " 610: 'sells',\n",
       " 611: 'sacked',\n",
       " 612: 'think',\n",
       " 613: 'different',\n",
       " 614: 'building',\n",
       " 615: 'commits',\n",
       " 616: 'mobile',\n",
       " 617: 'married',\n",
       " 618: 'gifts',\n",
       " 619: 'second',\n",
       " 620: 'mark',\n",
       " 621: 'posters',\n",
       " 622: 'kapoor',\n",
       " 623: 'wb',\n",
       " 624: 'art',\n",
       " 625: 'drivers',\n",
       " 626: 'force',\n",
       " 627: 'jawan',\n",
       " 628: 'sushant',\n",
       " 629: 'decide',\n",
       " 630: 'hotel',\n",
       " 631: 'traffic',\n",
       " 632: 'truck',\n",
       " 633: 'crpf',\n",
       " 634: 'private',\n",
       " 635: 'international',\n",
       " 636: 'lalu',\n",
       " 637: 'demands',\n",
       " 638: 'reliance',\n",
       " 639: 'bwood',\n",
       " 640: 'ranbir',\n",
       " 641: 'kargil',\n",
       " 642: 'missing',\n",
       " 643: 'releases',\n",
       " 644: 'policy',\n",
       " 645: 'malayalam',\n",
       " 646: 'personnel',\n",
       " 647: 'railway',\n",
       " 648: 'begins',\n",
       " 649: 'yadav',\n",
       " 650: 'detained',\n",
       " 651: 'users',\n",
       " 652: 'secy',\n",
       " 653: 'alleged',\n",
       " 654: 'approves',\n",
       " 655: 'status',\n",
       " 656: 'student',\n",
       " 657: 'ask',\n",
       " 658: 'lead',\n",
       " 659: 'amit',\n",
       " 660: 'rejects',\n",
       " 661: 'cows',\n",
       " 662: 'teachers',\n",
       " 663: 'passengers',\n",
       " 664: 'politics',\n",
       " 665: 'taapsee',\n",
       " 666: 'night',\n",
       " 667: 'posts',\n",
       " 668: 'jan',\n",
       " 669: 'kill',\n",
       " 670: 'ghaziabad',\n",
       " 671: 'kangana',\n",
       " 672: 'clears',\n",
       " 673: 'jagga',\n",
       " 674: 'anil',\n",
       " 675: 'poster',\n",
       " 676: 'deepika',\n",
       " 677: 'east',\n",
       " 678: 'encounter',\n",
       " 679: 'arrest',\n",
       " 680: 'demand',\n",
       " 681: 'getting',\n",
       " 682: 'killing',\n",
       " 683: 'fan',\n",
       " 684: 'event',\n",
       " 685: 'citizens',\n",
       " 686: 'fir',\n",
       " 687: 'molestation',\n",
       " 688: 'military',\n",
       " 689: 'actors',\n",
       " 690: 'good',\n",
       " 691: 'kg',\n",
       " 692: 'attacked',\n",
       " 693: 'triple',\n",
       " 694: 'jet',\n",
       " 695: 'toll',\n",
       " 696: 'rumours',\n",
       " 697: 'terrorists',\n",
       " 698: 'well',\n",
       " 699: 'live',\n",
       " 700: 'single',\n",
       " 701: 'having',\n",
       " 702: 'reach',\n",
       " 703: 'join',\n",
       " 704: 'hrs',\n",
       " 705: 'supreme',\n",
       " 706: 'elected',\n",
       " 707: 'pms',\n",
       " 708: 'order',\n",
       " 709: 'seen',\n",
       " 710: 'cbse',\n",
       " 711: 'selling',\n",
       " 712: 'delay',\n",
       " 713: 'link',\n",
       " 714: 'religious',\n",
       " 715: 'compensation',\n",
       " 716: 'facebook',\n",
       " 717: 'toilets',\n",
       " 718: 'remove',\n",
       " 719: 'uber',\n",
       " 720: 'judge',\n",
       " 721: 'yamuna',\n",
       " 722: 'starts',\n",
       " 723: 'bag',\n",
       " 724: 'sabha',\n",
       " 725: 'isi',\n",
       " 726: 'hindi',\n",
       " 727: 'cbfc',\n",
       " 728: 'alia',\n",
       " 729: 'ramdev',\n",
       " 730: 'buy',\n",
       " 731: 'stolen',\n",
       " 732: 'forces',\n",
       " 733: 'bollywood',\n",
       " 734: 'social',\n",
       " 735: 'took',\n",
       " 736: 'employees',\n",
       " 737: 'abduction',\n",
       " 738: 'law',\n",
       " 739: 'rise',\n",
       " 740: 'offer',\n",
       " 741: 'see',\n",
       " 742: 'atm',\n",
       " 743: 'june',\n",
       " 744: 'bad',\n",
       " 745: 'receives',\n",
       " 746: 'sports',\n",
       " 747: 'abu',\n",
       " 748: 'raping',\n",
       " 749: 'minor',\n",
       " 750: 'raped',\n",
       " 751: 'marks',\n",
       " 752: 'site',\n",
       " 753: 'anyone',\n",
       " 754: 'earn',\n",
       " 755: 'rumoured',\n",
       " 756: 'producer',\n",
       " 757: 'smuggling',\n",
       " 758: 'white',\n",
       " 759: 'fired',\n",
       " 760: 'shastri',\n",
       " 761: 'federer',\n",
       " 762: 'gang',\n",
       " 763: 'drug',\n",
       " 764: 'festival',\n",
       " 765: 'brother',\n",
       " 766: 'visit',\n",
       " 767: 'telugu',\n",
       " 768: 'harassment',\n",
       " 769: 'owaisi',\n",
       " 770: 'fires',\n",
       " 771: 'charges',\n",
       " 772: 'stealing',\n",
       " 773: 'jdu',\n",
       " 774: 'jasoos',\n",
       " 775: 'declared',\n",
       " 776: 'scores',\n",
       " 777: 'dangal',\n",
       " 778: 'stars',\n",
       " 779: 'club',\n",
       " 780: 'biopic',\n",
       " 781: 'developed',\n",
       " 782: 'highest',\n",
       " 783: 'employee',\n",
       " 784: 'through',\n",
       " 785: 'asked',\n",
       " 786: 'porn',\n",
       " 787: 'hrithik',\n",
       " 788: 'alliance',\n",
       " 789: 'model',\n",
       " 790: 'faces',\n",
       " 791: 'born',\n",
       " 792: 'rukh',\n",
       " 793: 'wifi',\n",
       " 794: 'fails',\n",
       " 795: 'sbi',\n",
       " 796: 'quality',\n",
       " 797: 'where',\n",
       " 798: 'among',\n",
       " 799: 'alleges',\n",
       " 800: 'march',\n",
       " 801: 'sold',\n",
       " 802: 'standoff',\n",
       " 803: 'reveals',\n",
       " 804: 'landing',\n",
       " 805: 'evm',\n",
       " 806: 'phones',\n",
       " 807: 'aircraft',\n",
       " 808: 'within',\n",
       " 809: 'plastic',\n",
       " 810: 'talks',\n",
       " 811: 'north',\n",
       " 812: 'education',\n",
       " 813: 'presidential',\n",
       " 814: 'wear',\n",
       " 815: 'lost',\n",
       " 816: 'oppose',\n",
       " 817: 'wall',\n",
       " 818: 'explain',\n",
       " 819: 'funding',\n",
       " 820: 'museum',\n",
       " 821: 'foreign',\n",
       " 822: 'digital',\n",
       " 823: 'complaints',\n",
       " 824: 'threatens',\n",
       " 825: 'separate',\n",
       " 826: 'quit',\n",
       " 827: 'yoga',\n",
       " 828: 'awards',\n",
       " 829: 'anthem',\n",
       " 830: 'stabbed',\n",
       " 831: 'shri',\n",
       " 832: 'rjd',\n",
       " 833: 'ties',\n",
       " 834: 'app',\n",
       " 835: 'chopper',\n",
       " 836: 'passenger',\n",
       " 837: 'am',\n",
       " 838: 'british',\n",
       " 839: 'grand',\n",
       " 840: 'been',\n",
       " 841: 'interest',\n",
       " 842: 'official',\n",
       " 843: 'which',\n",
       " 844: 'tests',\n",
       " 845: 'penalty',\n",
       " 846: 'lose',\n",
       " 847: 'responsible',\n",
       " 848: 'safety',\n",
       " 849: 'allows',\n",
       " 850: 'living',\n",
       " 851: 'contest',\n",
       " 852: 'released',\n",
       " 853: 'nearly',\n",
       " 854: 'wc',\n",
       " 855: 'service',\n",
       " 856: 'charge',\n",
       " 857: 'along',\n",
       " 858: 'fair',\n",
       " 859: 'casting',\n",
       " 860: 'putin',\n",
       " 861: 'hacked',\n",
       " 862: 'jat',\n",
       " 863: 'fraud',\n",
       " 864: 'flights',\n",
       " 865: 'told',\n",
       " 866: 'mandatory',\n",
       " 867: 'doing',\n",
       " 868: 'children',\n",
       " 869: 'move',\n",
       " 870: 'today',\n",
       " 871: 'planning',\n",
       " 872: 'sexually',\n",
       " 873: 'apologises',\n",
       " 874: 'talk',\n",
       " 875: 'ambassador',\n",
       " 876: 'blind',\n",
       " 877: 'cup',\n",
       " 878: 'human',\n",
       " 879: 'pakistani',\n",
       " 880: 'quota',\n",
       " 881: 'assaulted',\n",
       " 882: 'armed',\n",
       " 883: 'care',\n",
       " 884: 'short',\n",
       " 885: 'dig',\n",
       " 886: 'kumble',\n",
       " 887: 'hyderabad',\n",
       " 888: 'mps',\n",
       " 889: 'hai',\n",
       " 890: 'nuclear',\n",
       " 891: 'blames',\n",
       " 892: 'bid',\n",
       " 893: 'ktaka',\n",
       " 894: 'soon',\n",
       " 895: 'mayor',\n",
       " 896: 'same',\n",
       " 897: 'telangana',\n",
       " 898: 'cars',\n",
       " 899: 'title',\n",
       " 900: 'global',\n",
       " 901: 'results',\n",
       " 902: 'sister',\n",
       " 903: 'does',\n",
       " 904: 'economy',\n",
       " 905: 'reduce',\n",
       " 906: 'rti',\n",
       " 907: 'four',\n",
       " 908: 'vijay',\n",
       " 909: 'rishi',\n",
       " 910: 'saif',\n",
       " 911: 'runs',\n",
       " 912: 'date',\n",
       " 913: 'karnataka',\n",
       " 914: 'per',\n",
       " 915: 'kumars',\n",
       " 916: 'better',\n",
       " 917: 'music',\n",
       " 918: 'ticket',\n",
       " 919: 'boss',\n",
       " 920: 'know',\n",
       " 921: 'put',\n",
       " 922: 'longest',\n",
       " 923: 'letter',\n",
       " 924: 'feature',\n",
       " 925: 'class',\n",
       " 926: 'cag',\n",
       " 927: 'curb',\n",
       " 928: 'nirbhaya',\n",
       " 929: 'rajnath',\n",
       " 930: 'censor',\n",
       " 931: 'bars',\n",
       " 932: 'parking',\n",
       " 933: 'others',\n",
       " 934: 'roger',\n",
       " 935: 'martyred',\n",
       " 936: 'ngo',\n",
       " 937: 'mosque',\n",
       " 938: 'photo',\n",
       " 939: 'rescued',\n",
       " 940: 'sanjay',\n",
       " 941: 'groups',\n",
       " 942: 'petition',\n",
       " 943: 'july',\n",
       " 944: 'trains',\n",
       " 945: 'marries',\n",
       " 946: 'proposed',\n",
       " 947: 'there',\n",
       " 948: 'personal',\n",
       " 949: 'infosys',\n",
       " 950: 'stand',\n",
       " 951: 'carrying',\n",
       " 952: 'instead',\n",
       " 953: 'sexual',\n",
       " 954: 'mumbais',\n",
       " 955: 'seek',\n",
       " 956: 'info',\n",
       " 957: 'deposits',\n",
       " 958: 'return',\n",
       " 959: 'prank',\n",
       " 960: 'lawyer',\n",
       " 961: 'wedding',\n",
       " 962: 'forced',\n",
       " 963: 'avoid',\n",
       " 964: 'jailed',\n",
       " 965: 'self',\n",
       " 966: 'champions',\n",
       " 967: 'trophy',\n",
       " 968: 'needs',\n",
       " 969: 'sharma',\n",
       " 970: 'tree',\n",
       " 971: 'highway',\n",
       " 972: 'tour',\n",
       " 973: 'kin',\n",
       " 974: 'teen',\n",
       " 975: 'meets',\n",
       " 976: 'commission',\n",
       " 977: 'village',\n",
       " 978: 'wearing',\n",
       " 979: 'close',\n",
       " 980: 'tea',\n",
       " 981: 'bridge',\n",
       " 982: 'tickets',\n",
       " 983: 'centres',\n",
       " 984: 'surgery',\n",
       " 985: 'legal',\n",
       " 986: 'korea',\n",
       " 987: 'parrikar',\n",
       " 988: 'dec',\n",
       " 989: 'singers',\n",
       " 990: 'protests',\n",
       " 991: 'advani',\n",
       " 992: 'sania',\n",
       " 993: 'celebrate',\n",
       " 994: 'find',\n",
       " 995: 'football',\n",
       " 996: 'college',\n",
       " 997: 'overseas',\n",
       " 998: 'wishes',\n",
       " 999: 'ahead',\n",
       " 1000: 'intl',\n",
       " ...}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_target_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([5,4,3,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d6c57ef52e2efd1c05c16360dde36ad734d1ea6e1782145a484aca776c2e3cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
