{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook we will build the model and see some predicted examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>administration union territory daman diu revok...</td>\n",
       "      <td>sostok daman diu revokes mandatory rakshabandh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>malaika arora slammed instagram user trolled d...</td>\n",
       "      <td>sostok malaika slams user who trolled her for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>indira gandhi institute medical sciences igims...</td>\n",
       "      <td>sostok virgin now corrected to unmarried in ig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>lashkaretaibas kashmir commander abu dujana ki...</td>\n",
       "      <td>sostok aaj aapne pakad liya let man dujana bef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>hotels maharashtra train staff spot signs sex ...</td>\n",
       "      <td>sostok hotel staff to get training to spot sig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0  administration union territory daman diu revok...   \n",
       "1           1  malaika arora slammed instagram user trolled d...   \n",
       "2           2  indira gandhi institute medical sciences igims...   \n",
       "3           3  lashkaretaibas kashmir commander abu dujana ki...   \n",
       "4           4  hotels maharashtra train staff spot signs sex ...   \n",
       "\n",
       "                                             summary  \n",
       "0  sostok daman diu revokes mandatory rakshabandh...  \n",
       "1  sostok malaika slams user who trolled her for ...  \n",
       "2  sostok virgin now corrected to unmarried in ig...  \n",
       "3  sostok aaj aapne pakad liya let man dujana bef...  \n",
       "4  sostok hotel staff to get training to spot sig...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./dataset/cleaned_news_summary.csv\")\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset in the train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.text, data.summary, test_size=0.2, random_state=101, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all the tensorflow libraries for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed, Concatenate, Bidirectional\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from attention_my import AttentionLayer\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "physical_devices\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# run_opts = tf.Run(report_tensor_allocations_upon_oom = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next converting text to sequence of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokenizer = Tokenizer()\n",
    "X_tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "X_train_seq = X_tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = X_tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train = pad_sequences(X_train_seq, maxlen = max_len_news, padding='post')\n",
    "X_test = pad_sequences(X_test_seq, maxlen = max_len_news, padding='post')\n",
    "\n",
    "news_vocab_size = len(X_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh=2\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_train))\n",
    "\n",
    "y_train_seq = y_tokenizer.texts_to_sequences(y_train)\n",
    "y_test_seq = y_tokenizer.texts_to_sequences(y_test)\n",
    "\n",
    "y_train = pad_sequences(y_train_seq, maxlen=max_len_headline, padding='post')\n",
    "y_test = pad_sequences(y_test_seq, maxlen=max_len_headline, padding='post')\n",
    "y_voc_size = len(y_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3516, 3516)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_counts['eostok'], len(y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 47)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 47, 100)      1946400     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 47, 300),    481200      ['embedding[0][0]']              \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 47, 300),    721200      ['lstm[0][0]']                   \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 100)    776200      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 47, 300),    721200      ['lstm_1[0][0]']                 \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 300),  481200      ['embedding_1[0][0]',            \n",
      "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " attention_layer (AttentionLaye  ((None, None, 300),  180300     ['lstm_2[0][0]',                 \n",
      " r)                              (None, None, 47))                'lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, None, 600)    0           ['lstm_3[0][0]',                 \n",
      "                                                                  'attention_layer[0][0]']        \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 7762)  4664962     ['concat_layer[0][0]']           \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,972,662\n",
      "Trainable params: 9,972,662\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "latent_dim=300\n",
    "emb_dim=100\n",
    "\n",
    "enc_inputs = Input(shape=(max_len_news,))\n",
    "embedding1 = Embedding(news_vocab_size,emb_dim, trainable=True)(enc_inputs)\n",
    "\n",
    "lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.3, recurrent_dropout=0.2)\n",
    "enc_output1, h1, c1 = lstm1(embedding1)\n",
    "\n",
    "lstm2 = LSTM(latent_dim, return_sequences=True,return_state=True, dropout=0.3, recurrent_dropout=0.2)\n",
    "enc_output2, h2, c2 = lstm2(enc_output1)\n",
    "\n",
    "lstm3 = LSTM(latent_dim, return_sequences=True,return_state=True, dropout=0.3, recurrent_dropout=0.2)\n",
    "enc_outputs, h3, c3 = lstm3(enc_output2)\n",
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(None, ))\n",
    "dec_embedding = Embedding(y_voc_size, emb_dim, trainable=True)\n",
    "dec_emb_out = dec_embedding(decoder_inputs)\n",
    "\n",
    "dec_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.3, recurrent_dropout=0.2)\n",
    "decoder_outputs, fwd_state, back_state = dec_lstm(dec_emb_out, initial_state = [h3, c3])\n",
    "\n",
    "\n",
    "\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_state = attn_layer([enc_outputs, decoder_outputs])\n",
    "\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "model = Model([enc_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy',mode='max',verbose=1,patience=40)\n",
    "rl = ReduceLROnPlateau(monitor='val_accuracy',mode='max',verbose=1,patience=5,factor=0.1,min_lr=0.001)\n",
    "mc = ModelCheckpoint('checkpoint/',monitor='val_accuracy',verbose=1,mode='max',save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 6.4889 - accuracy: 0.2007\n",
      "Epoch 1: val_accuracy improved from -inf to 0.32576, saving model to checkpoint\\\n",
      "INFO:tensorflow:Assets written to: checkpoint\\assets\n",
      "55/55 [==============================] - 45s 672ms/step - loss: 6.4889 - accuracy: 0.2007 - val_loss: 5.0628 - val_accuracy: 0.3258 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 5.8868 - accuracy: 0.2696\n",
      "Epoch 2: val_accuracy improved from 0.32576 to 0.35985, saving model to checkpoint\\\n",
      "INFO:tensorflow:Assets written to: checkpoint\\assets\n",
      "55/55 [==============================] - 36s 657ms/step - loss: 5.8868 - accuracy: 0.2696 - val_loss: 4.8986 - val_accuracy: 0.3598 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 5.6950 - accuracy: 0.2804\n",
      "Epoch 3: val_accuracy did not improve from 0.35985\n",
      "55/55 [==============================] - 30s 549ms/step - loss: 5.6950 - accuracy: 0.2804 - val_loss: 4.9104 - val_accuracy: 0.3503 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 5.5470 - accuracy: 0.2836\n",
      "Epoch 4: val_accuracy did not improve from 0.35985\n",
      "55/55 [==============================] - 30s 552ms/step - loss: 5.5470 - accuracy: 0.2836 - val_loss: 4.8724 - val_accuracy: 0.3507 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 5.4148 - accuracy: 0.2846\n",
      "Epoch 5: val_accuracy improved from 0.35985 to 0.36638, saving model to checkpoint\\\n",
      "INFO:tensorflow:Assets written to: checkpoint\\assets\n",
      "55/55 [==============================] - 37s 677ms/step - loss: 5.4148 - accuracy: 0.2846 - val_loss: 4.7854 - val_accuracy: 0.3664 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 5.2907 - accuracy: 0.2880\n",
      "Epoch 6: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 542ms/step - loss: 5.2907 - accuracy: 0.2880 - val_loss: 4.7668 - val_accuracy: 0.3575 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 5.1645 - accuracy: 0.2895\n",
      "Epoch 7: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 29s 534ms/step - loss: 5.1645 - accuracy: 0.2895 - val_loss: 4.7840 - val_accuracy: 0.3545 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 5.0394 - accuracy: 0.2920\n",
      "Epoch 8: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 552ms/step - loss: 5.0394 - accuracy: 0.2920 - val_loss: 4.7509 - val_accuracy: 0.3620 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.9141 - accuracy: 0.2938\n",
      "Epoch 9: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 544ms/step - loss: 4.9141 - accuracy: 0.2938 - val_loss: 4.8005 - val_accuracy: 0.3535 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.7922 - accuracy: 0.2976\n",
      "Epoch 10: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 542ms/step - loss: 4.7922 - accuracy: 0.2976 - val_loss: 4.8300 - val_accuracy: 0.3534 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.6702 - accuracy: 0.2987\n",
      "Epoch 11: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 549ms/step - loss: 4.6702 - accuracy: 0.2987 - val_loss: 4.8633 - val_accuracy: 0.3521 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.5360 - accuracy: 0.3021\n",
      "Epoch 12: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 29s 531ms/step - loss: 4.5360 - accuracy: 0.3021 - val_loss: 4.8386 - val_accuracy: 0.3613 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.4066 - accuracy: 0.3039\n",
      "Epoch 13: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 569ms/step - loss: 4.4066 - accuracy: 0.3039 - val_loss: 4.8782 - val_accuracy: 0.3534 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.2761 - accuracy: 0.3084\n",
      "Epoch 14: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 539ms/step - loss: 4.2761 - accuracy: 0.3084 - val_loss: 4.8855 - val_accuracy: 0.3557 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.1453 - accuracy: 0.3132\n",
      "Epoch 15: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 29s 536ms/step - loss: 4.1453 - accuracy: 0.3132 - val_loss: 4.9139 - val_accuracy: 0.3563 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 4.0136 - accuracy: 0.3174\n",
      "Epoch 16: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 32s 590ms/step - loss: 4.0136 - accuracy: 0.3174 - val_loss: 4.9506 - val_accuracy: 0.3501 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.8826 - accuracy: 0.3261\n",
      "Epoch 17: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 32s 576ms/step - loss: 3.8826 - accuracy: 0.3261 - val_loss: 4.9735 - val_accuracy: 0.3523 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.7567 - accuracy: 0.3340\n",
      "Epoch 18: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 547ms/step - loss: 3.7567 - accuracy: 0.3340 - val_loss: 4.9920 - val_accuracy: 0.3504 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.6294 - accuracy: 0.3441\n",
      "Epoch 19: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 569ms/step - loss: 3.6294 - accuracy: 0.3441 - val_loss: 5.0108 - val_accuracy: 0.3523 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.5027 - accuracy: 0.3563\n",
      "Epoch 20: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 554ms/step - loss: 3.5027 - accuracy: 0.3563 - val_loss: 5.0482 - val_accuracy: 0.3511 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.3751 - accuracy: 0.3699\n",
      "Epoch 21: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 553ms/step - loss: 3.3751 - accuracy: 0.3699 - val_loss: 5.0360 - val_accuracy: 0.3546 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.2597 - accuracy: 0.3848\n",
      "Epoch 22: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 572ms/step - loss: 3.2597 - accuracy: 0.3848 - val_loss: 5.0637 - val_accuracy: 0.3536 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.1434 - accuracy: 0.4028\n",
      "Epoch 23: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 539ms/step - loss: 3.1434 - accuracy: 0.4028 - val_loss: 5.0854 - val_accuracy: 0.3540 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 3.0204 - accuracy: 0.4200\n",
      "Epoch 24: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 562ms/step - loss: 3.0204 - accuracy: 0.4200 - val_loss: 5.1364 - val_accuracy: 0.3479 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.9024 - accuracy: 0.4374\n",
      "Epoch 25: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 557ms/step - loss: 2.9024 - accuracy: 0.4374 - val_loss: 5.1368 - val_accuracy: 0.3542 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.7963 - accuracy: 0.4556\n",
      "Epoch 26: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 545ms/step - loss: 2.7963 - accuracy: 0.4556 - val_loss: 5.2014 - val_accuracy: 0.3500 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.6797 - accuracy: 0.4748\n",
      "Epoch 27: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 32s 577ms/step - loss: 2.6797 - accuracy: 0.4748 - val_loss: 5.1942 - val_accuracy: 0.3522 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.5648 - accuracy: 0.4963\n",
      "Epoch 28: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 568ms/step - loss: 2.5648 - accuracy: 0.4963 - val_loss: 5.2305 - val_accuracy: 0.3485 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.4701 - accuracy: 0.5141\n",
      "Epoch 29: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 32s 582ms/step - loss: 2.4701 - accuracy: 0.5141 - val_loss: 5.2991 - val_accuracy: 0.3441 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.3590 - accuracy: 0.5385\n",
      "Epoch 30: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 557ms/step - loss: 2.3590 - accuracy: 0.5385 - val_loss: 5.3176 - val_accuracy: 0.3404 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.2686 - accuracy: 0.5541\n",
      "Epoch 31: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 561ms/step - loss: 2.2686 - accuracy: 0.5541 - val_loss: 5.3172 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.1591 - accuracy: 0.5742\n",
      "Epoch 32: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 32s 577ms/step - loss: 2.1591 - accuracy: 0.5742 - val_loss: 5.3931 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 2.0772 - accuracy: 0.5880\n",
      "Epoch 33: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 551ms/step - loss: 2.0772 - accuracy: 0.5880 - val_loss: 5.3686 - val_accuracy: 0.3454 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.9756 - accuracy: 0.6128\n",
      "Epoch 34: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 558ms/step - loss: 1.9756 - accuracy: 0.6128 - val_loss: 5.4104 - val_accuracy: 0.3446 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.8884 - accuracy: 0.6299\n",
      "Epoch 35: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 554ms/step - loss: 1.8884 - accuracy: 0.6299 - val_loss: 5.4541 - val_accuracy: 0.3445 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.8052 - accuracy: 0.6479\n",
      "Epoch 36: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 32s 576ms/step - loss: 1.8052 - accuracy: 0.6479 - val_loss: 5.4652 - val_accuracy: 0.3442 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.7175 - accuracy: 0.6661\n",
      "Epoch 37: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 557ms/step - loss: 1.7175 - accuracy: 0.6661 - val_loss: 5.5206 - val_accuracy: 0.3414 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.6428 - accuracy: 0.6788\n",
      "Epoch 38: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 547ms/step - loss: 1.6428 - accuracy: 0.6788 - val_loss: 5.5101 - val_accuracy: 0.3433 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.5697 - accuracy: 0.6970\n",
      "Epoch 39: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 543ms/step - loss: 1.5697 - accuracy: 0.6970 - val_loss: 5.5514 - val_accuracy: 0.3445 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.4901 - accuracy: 0.7140\n",
      "Epoch 40: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 566ms/step - loss: 1.4901 - accuracy: 0.7140 - val_loss: 5.5668 - val_accuracy: 0.3427 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.4207 - accuracy: 0.7274\n",
      "Epoch 41: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 556ms/step - loss: 1.4207 - accuracy: 0.7274 - val_loss: 5.5846 - val_accuracy: 0.3439 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.3556 - accuracy: 0.7412\n",
      "Epoch 42: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 571ms/step - loss: 1.3556 - accuracy: 0.7412 - val_loss: 5.6107 - val_accuracy: 0.3438 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.2813 - accuracy: 0.7564\n",
      "Epoch 43: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 558ms/step - loss: 1.2813 - accuracy: 0.7564 - val_loss: 5.6688 - val_accuracy: 0.3410 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.2101 - accuracy: 0.7709\n",
      "Epoch 44: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 31s 568ms/step - loss: 1.2101 - accuracy: 0.7709 - val_loss: 5.6452 - val_accuracy: 0.3443 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 1.1608 - accuracy: 0.7839\n",
      "Epoch 45: val_accuracy did not improve from 0.36638\n",
      "55/55 [==============================] - 30s 548ms/step - loss: 1.1608 - accuracy: 0.7839 - val_loss: 5.6883 - val_accuracy: 0.3441 - lr: 0.0010\n",
      "Epoch 45: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history=model.fit([X_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,epochs=50,batch_size=64, callbacks=[es, rl, mc], validation_data=([X_test,y_test[:,:-1]], y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As we notice that we get the final accuracy of 78.4 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot \n",
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "pyplot.legend() \n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index = y_tokenizer.index_word\n",
    "reverse_news_words_index = X_tokenizer.index_word\n",
    "target_word_index = y_tokenizer.word_index\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs = enc_inputs, outputs = [enc_outputs, h3, c3])\n",
    "\n",
    "decoder_h = Input(shape=(latent_dim,))\n",
    "decoder_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_len_news, latent_dim))\n",
    "\n",
    "\n",
    "dec_emb2 = dec_embedding(decoder_inputs)\n",
    "\n",
    "dec_output2, dec_h2, dec_c2 = dec_lstm(dec_emb2, initial_state=[decoder_h, decoder_c])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "attn_out_inf, attn_state_inf = attn_layer([decoder_hidden_state_input, dec_output2])\n",
    "\n",
    "dec_inf_concat = Concatenate(axis=-1, name='concat')([dec_output2, attn_out_inf])\n",
    "\n",
    "\n",
    "dec_output2 = decoder_dense(dec_inf_concat)\n",
    "\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input, decoder_h, decoder_c], [dec_output2] + [dec_h2, dec_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 100)    776200      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 300),  481200      ['embedding_1[1][0]',            \n",
      "                                 (None, 300),                     'input_3[0][0]',                \n",
      "                                 (None, 300)]                     'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 47, 300)]    0           []                               \n",
      "                                                                                                  \n",
      " attention_layer (AttentionLaye  ((None, None, 300),  180300     ['input_5[0][0]',                \n",
      " r)                              (None, None, 47))                'lstm_3[1][0]']                 \n",
      "                                                                                                  \n",
      " concat (Concatenate)           (None, None, 600)    0           ['lstm_3[1][0]',                 \n",
      "                                                                  'attention_layer[1][0]']        \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 7762)  4664962     ['concat[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,102,662\n",
      "Trainable params: 6,102,662\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_sequence):\n",
    "    e_out, e_h, e_c = encoder_model(input_sequence)\n",
    "\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    target_seq[0,0] = target_word_index['sostok'] ## We always start with sostok\n",
    "\n",
    "    stop_condition = False\n",
    "\n",
    "\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        \n",
    "        sample_token_index = np.argmax(output_tokens[0,-1,:])\n",
    "        sampled_token = reverse_target_word_index[sample_token_index]\n",
    "\n",
    "        if sampled_token!='eostok':\n",
    "            decoded_sentence+= ' ' + sampled_token\n",
    "\n",
    "        if (sampled_token=='eostok' or len(decoded_sentence.split())>=(max_len_headline-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1,1))\n",
    "\n",
    "        target_seq[0,0] = target_word_index[sampled_token]\n",
    "\n",
    "\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "        newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if(i!=0):\n",
    "        newString=newString+reverse_news_words_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets look at some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: six months stabbed left playing hand czech tennis player petra kvitova first tournament classic sunday world number 12 kvitova playing second tournament since december incident beat australian 46 63 63 birmingham kvitova returned action french open late may \n",
      "Original summary: czech tennis player wins title months after being stabbed \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Predicted summary:  what is hold icj from icj in icj in jadhav\n",
      "\n",
      "\n",
      "Review: farmers 78 villages maharashtra reportedly planning go indefinite fast protest alleged acquisition farm land industrial corridor despite project getting scaled original size 78 villages activists said officials maintained planning land acquisition \n",
      "Original summary: maha farmers to fast to protest land acquisition \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Predicted summary:  delhi man to get in protest in delhi bjp\n",
      "\n",
      "\n",
      "Review: launching desh ka aam scheme thursday pm narendra modi said dream see person wears slippers fly lives middle class aviation considered domain select changed added \n",
      "Original summary: wanted to see people wearing on \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predicted summary:  modi should pm modi to relook in modi katrinas modi\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 4):\n",
    "  print(\"Review:\",seq2text(X_test[i]))\n",
    "  print(\"Original summary:\",seq2summary(y_test[i]))\n",
    "  print(\"Predicted summary:\",decode_sequence(X_test[i].reshape(1,max_len_news)))\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d6c57ef52e2efd1c05c16360dde36ad734d1ea6e1782145a484aca776c2e3cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
